{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227a9be7",
   "metadata": {},
   "source": [
    "### Information\n",
    "Chat GPT was used in some parts of the notebook, but this was explicitly mentioned in the relevant sections. In addition, the documentation was further optimised with the help of AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815ea17",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n",
    "This section imports all the essential libraries for data analysis, visualization, preprocessing, and model training. Additionally, setting a fixed random seed (SEED) ensures reproducibility of results, and configuring TensorFlow’s threading options guarantees deterministic execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6587ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "SEED = 12345\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bf4c8b",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "The dataset is loaded from a CSV file named data.csv using pandas. The semicolon is specified as the separator since the file uses “;” instead of a comma to separate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "78429bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "43174033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.00</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.80</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.67</td>\n",
       "      <td>0</td>\n",
       "      <td>13.90</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.00</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.80</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.00</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.40</td>\n",
       "      <td>0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0</td>\n",
       "      <td>13.90</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  Course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                             1                       1   \n",
       "1                             1                       1   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             0                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                          122.00            1                      19   \n",
       "1                          160.00            1                       1   \n",
       "2                          122.00            1                      37   \n",
       "3                          122.00            1                      38   \n",
       "4                          100.00            1                      37   \n",
       "\n",
       "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                      12  ...                                    0   \n",
       "1                       3  ...                                    0   \n",
       "2                      37  ...                                    0   \n",
       "3                      37  ...                                    0   \n",
       "4                      38  ...                                    0   \n",
       "\n",
       "   Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    6   \n",
       "4                                    6   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       0   \n",
       "3                                      10   \n",
       "4                                       6   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    0                              0.00   \n",
       "1                                    6                             13.67   \n",
       "2                                    0                              0.00   \n",
       "3                                    5                             12.40   \n",
       "4                                    6                             13.00   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0              10.80   \n",
       "1                                               0              13.90   \n",
       "2                                               0              10.80   \n",
       "3                                               0               9.40   \n",
       "4                                               0              13.90   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0            1.40  1.74   Dropout  \n",
       "1           -0.30  0.79  Graduate  \n",
       "2            1.40  1.74   Dropout  \n",
       "3           -0.80 -3.12  Graduate  \n",
       "4           -0.30  0.79  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56549658",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "In this section, the dataset is prepared and cleaned for model training. All data undergo the same preprocessing steps to ensure consistency. GPT was used only to suggest possible mapping strategies for creating new columns, and only the descriptions of the data values (e.g., what the numbers like 1, 2, or 3 represent) were provided so that meaningful columns could be created. No actual data was shared with the AI. The reference code for the data mapping logic was adapted from the following source: https://stackoverflow.com/questions/19913659/how-do-i-create-a-new-column-where-the-values-are-selected-based-on-an-existing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23e794",
   "metadata": {},
   "source": [
    "The Marital status column is converted into three new binary columns, single, partnered, and previously_partnered, to simplify categorical data. The original column is then removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "81c8a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"single\"] = (df[\"Marital status\"] == 1).astype(int)\n",
    "df[\"partnered\"] = df[\"Marital status\"].isin([2, 5]).astype(int)\n",
    "df[\"prev_partnered\"] = df[\"Marital status\"].isin([3, 4, 6]).astype(int)\n",
    "df = df.drop(columns=[\"Marital status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51ab0a",
   "metadata": {},
   "source": [
    "The Application mode column is mapped into three new binary columns, admission_general, admission_transfer, and admission_special/international. to group different admission types into broader categories. The original column is then removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a89825a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"admission_general\"] = df[\"Application mode\"].isin([1, 17, 18]).astype(int)\n",
    "df[\"admission_transfer\"] = df[\"Application mode\"].isin([42, 43, 44, 51, 53, 57]).astype(int)\n",
    "df[\"admission_special/international\"] = df[\"Application mode\"].isin([2, 5, 7, 10, 15, 16, 26, 27, 39]).astype(int)\n",
    "df = df.drop(columns=[\"Application mode\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e28b72",
   "metadata": {},
   "source": [
    "The Application order column is transformed into a binary column called high_priority, indicating whether the application was among the top three choices. The original column is then removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "094f54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"high_priority\"] = (df[\"Application order\"] <= 3).astype(int)\n",
    "df = df.drop(columns=[\"Application order\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4763dc15",
   "metadata": {},
   "source": [
    "The Course column is mapped into three new binary columns, studyfield_stem, studyfield_business_social, and studyfield_arts&comm, to group study programs into broader academic categories. The original column is then removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "110e48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"studyfield_stem\"] = df[\"Course\"].isin([33, 9119, 9085]).astype(int)\n",
    "df[\"studyfield_business_social\"] = df[\"Course\"].isin([9147, 9991, 9670, 9254, 8014, 9238, 9853]).astype(int)\n",
    "df[\"studyfield_arts&comm\"] = df[\"Course\"].isin([171, 9070, 9773, 9130, 9500, 9556]).astype(int)\n",
    "df = df.drop(columns=[\"Course\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2654ec",
   "metadata": {},
   "source": [
    "The Daytime/evening attendance column is renamed to is_daytime to simplify interpretation of study attendance type. The original column is then removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6b4ad6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_daytime\"] = df[\"Daytime/evening attendance\\t\"]\n",
    "df = df.drop(columns=[\"Daytime/evening attendance\\t\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e7664",
   "metadata": {},
   "source": [
    "The Previous qualification column is mapped into three new binary columns, prevqual_basic, prevqual_secondary, and prevqual_higher, to categorize students by their highest level of prior education. The original column is then removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fe9a403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prevqual_basic\"] = df[\"Previous qualification\"].isin([9, 10, 12, 14, 15, 19, 38]).astype(int)\n",
    "df[\"prevqual_secondary\"] = df[\"Previous qualification\"].isin([1, 39]).astype(int)\n",
    "df[\"prevqual_higher\"] = df[\"Previous qualification\"].isin([2, 3, 4, 5, 6, 40, 42, 43]).astype(int)\n",
    "df = df.drop(columns=[\"Previous qualification\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16752efe",
   "metadata": {},
   "source": [
    "The Nationality column is mapped into five new binary columns, nationality_europe, nationality_africa, nationality_south_america, nationality_north_america, and nationality_asia, to group students by their continent of origin. The original column is then removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "950ef866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nationality_europe\"] = df[\"Nacionality\"].isin([1, 2, 6, 11, 13, 14, 17, 62, 100, 103, 105]).astype(int)\n",
    "df[\"nationality_africa\"] = df[\"Nacionality\"].isin([21, 22, 24, 25, 26]).astype(int)\n",
    "df[\"nationality_south_america\"] = df[\"Nacionality\"].isin([41, 109]).astype(int)\n",
    "df[\"nationality_north_america\"] = df[\"Nacionality\"].isin([101, 108]).astype(int)\n",
    "df[\"nationality_asia\"] = df[\"Nacionality\"].isin([32]).astype(int)\n",
    "\n",
    "df = df.drop(columns=[\"Nacionality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b8c0fd",
   "metadata": {},
   "source": [
    "The Mother's qualification column is mapped into three new binary columns, mother_qualification_basic, mother_qualification_secondary, and mother_qualification_higher, to classify the mother's highest education level. The original column is then removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a50a5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mother_qualification_basic\"] = df[\"Mother's qualification\"].isin([9, 10, 11, 12, 14, 18, 19, 22, 26, 27, 29, 30, 35, 36, 37, 38]).astype(int)\n",
    "df[\"mother_qualification_secondary\"] = df[\"Mother's qualification\"].isin([1, 39]).astype(int)\n",
    "df[\"mother_qualification_higher\"] = df[\"Mother's qualification\"].isin([2, 3, 4, 5, 6, 40, 41, 42, 43, 44]).astype(int)\n",
    "df = df.drop(columns=[\"Mother's qualification\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da537f3",
   "metadata": {},
   "source": [
    "The Father's qualification column is mapped into three new binary columns, father_qualification_basic, father_qualification_secondary, and father_qualification_higher, to categorize the father's highest level of education. The original column is then removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c6498aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"father_qualification_basic\"] = df[\"Father's qualification\"].isin([9, 10, 11, 12, 13, 14, 18, 19, 20, 22, 25, 26, 27, 29, 30, 31, 33, 35, 36, 37, 38]).astype(int)\n",
    "df[\"father_qualification_secondary\"] = df[\"Father's qualification\"].isin([1, 39]).astype(int)\n",
    "df[\"father_qualification_higher\"] = df[\"Father's qualification\"].isin([2, 3, 4, 5, 6, 40, 41, 42, 43, 44]).astype(int)\n",
    "df = df.drop(columns=[\"Father's qualification\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9781628",
   "metadata": {},
   "source": [
    "The Mother's occupation column is mapped into four new binary columns, mother_occ_academic, mother_occ_technical_admin, mother_occ_service_manual, and mother_occ_unskilled_other, to group occupations by type and skill level. The original column is then removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e590660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mother_occ_academic\"] = df[\"Mother's occupation\"].isin([1, 2, 122, 123, 125]).astype(int)\n",
    "df[\"mother_occ_technical_admin\"] = df[\"Mother's occupation\"].isin([3, 4, 131, 132, 134, 141, 143, 144]).astype(int)\n",
    "df[\"mother_occ_service_manual\"] = df[\"Mother's occupation\"].isin([5, 6, 7, 8, 151, 152, 153, 171, 173, 175, 194]).astype(int)\n",
    "df[\"mother_occ_unskilled_other\"] = df[\"Mother's occupation\"].isin([0, 9, 10, 90, 99, 191, 192, 193]).astype(int)\n",
    "df = df.drop(columns=[\"Mother's occupation\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95afe103",
   "metadata": {},
   "source": [
    "The Father's occupation column is mapped into four new binary columns, father_occ_academic, father_occ_technical_admin, father_occ_service_manual, and father_occ_unskilled_other, to categorize occupations by type and skill level. The original column is then removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6b8a7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"father_occ_academic\"] = df[\"Father's occupation\"].isin([1, 2, 101, 102, 103, 112, 114, 121, 122, 123, 124, 135]).astype(int)\n",
    "df[\"father_occ_technical_admin\"] = df[\"Father's occupation\"].isin([3, 4, 131, 132, 134, 141, 143, 144]).astype(int)\n",
    "df[\"father_occ_service_manual\"] = df[\"Father's occupation\"].isin([5, 6, 7, 8, 151, 152, 153, 154, 161, 163, 171, 172, 174, 175, 181, 182, 183, 194, 195]).astype(int)\n",
    "df[\"father_occ_unskilled_other\"] = df[\"Father's occupation\"].isin([0, 9, 10, 90, 99, 192, 193]).astype(int)\n",
    "df = df.drop(columns=[\"Father's occupation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554d6326",
   "metadata": {},
   "source": [
    "A new column, avg_grade, is created by calculating the average of the grades from the first and second semesters. This provides a single metric representing each student’s overall academic performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "146d54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avg_grade\"] = ((df[\"Curricular units 1st sem (grade)\"] + df[\"Curricular units 2nd sem (grade)\"]) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c97c8e1",
   "metadata": {},
   "source": [
    "The success_rate column is created by dividing the total number of approved curricular units by the total number of enrolled units across both semesters, rounded to two decimal places. This represents each student’s academic success ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "14fdc355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"success_rate\"] = (((df[\"Curricular units 1st sem (approved)\"] + df[\"Curricular units 2nd sem (approved)\"]) /(df[\"Curricular units 1st sem (enrolled)\"] + df[\"Curricular units 2nd sem (enrolled)\"])).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece743ad",
   "metadata": {},
   "source": [
    "The total_enrolled column is created by summing the number of curricular units a student was enrolled in during the first and second semesters, providing the total course load for the academic year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "813fb712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"total_enrolled\"] = (df[\"Curricular units 1st sem (enrolled)\"] + df[\"Curricular units 2nd sem (enrolled)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d64222f",
   "metadata": {},
   "source": [
    "The no_evaluation_total column is created by adding the number of curricular units without evaluations from both semesters, indicating how many enrolled courses were not assessed overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f515b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"no_evaluation_total\"] = (df[\"Curricular units 1st sem (without evaluations)\"] + df[\"Curricular units 2nd sem (without evaluations)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8596ee",
   "metadata": {},
   "source": [
    "After deriving summary features such as avg_grade, success_rate, total_enrolled, and no_evaluation_total, all original semester-specific columns are removed to simplify the dataset and avoid redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "16e14386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\n",
    "    \"Curricular units 1st sem (credited)\",\n",
    "    \"Curricular units 1st sem (enrolled)\",\n",
    "    \"Curricular units 1st sem (evaluations)\",\n",
    "    \"Curricular units 1st sem (approved)\",\n",
    "    \"Curricular units 1st sem (without evaluations)\",\n",
    "    \"Curricular units 2nd sem (credited)\",\n",
    "    \"Curricular units 2nd sem (enrolled)\",\n",
    "    \"Curricular units 2nd sem (evaluations)\",\n",
    "    \"Curricular units 2nd sem (approved)\",\n",
    "    \"Curricular units 2nd sem (without evaluations)\",\n",
    "    \"Curricular units 1st sem (grade)\",\n",
    "    \"Curricular units 2nd sem (grade)\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8baf68",
   "metadata": {},
   "source": [
    "### Target Variable Encoding\n",
    "The Target column is converted into a numerical column called prediction, where categorical outcomes are mapped as follows: Dropout = 0, Enrolled = 1, and Graduate = 2. The original Target column is then removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "48ba3a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mani\\AppData\\Local\\Temp\\ipykernel_6468\\4092551096.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['prediction'] = df['Target'].replace({\n"
     ]
    }
   ],
   "source": [
    "df['prediction'] = df['Target'].replace({\n",
    "    'Dropout': 0,\n",
    "    'Enrolled': 1,\n",
    "    'Graduate': 2\n",
    "})\n",
    "df = df.drop(columns=['Target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6ea73",
   "metadata": {},
   "source": [
    "### Target Distribution Check\n",
    "\n",
    "This command displays the frequency of each class within the prediction column, allowing verification of how many students belong to each outcome category (Dropout, Enrolled, Graduate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3082d0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "2    2209\n",
       "0    1421\n",
       "1     794\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d77ad",
   "metadata": {},
   "source": [
    "### Missing Values Check\n",
    "\n",
    "All numerical columns, except involves_counterfeit, are selected to check for missing values. The code prints the number of missing entries per column and the total number of missing values across the dataset, helping identify data completeness issues before model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "21d15b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admission grade                      0\n",
      "Age at enrollment                    0\n",
      "Debtor                               0\n",
      "Displaced                            0\n",
      "Educational special needs            0\n",
      "GDP                                  0\n",
      "Gender                               0\n",
      "Inflation rate                       0\n",
      "International                        0\n",
      "Previous qualification (grade)       0\n",
      "Scholarship holder                   0\n",
      "Tuition fees up to date              0\n",
      "Unemployment rate                    0\n",
      "admission_general                    0\n",
      "admission_special/international      0\n",
      "admission_transfer                   0\n",
      "avg_grade                            0\n",
      "father_occ_academic                  0\n",
      "father_occ_service_manual            0\n",
      "father_occ_technical_admin           0\n",
      "father_occ_unskilled_other           0\n",
      "father_qualification_basic           0\n",
      "father_qualification_higher          0\n",
      "father_qualification_secondary       0\n",
      "high_priority                        0\n",
      "is_daytime                           0\n",
      "mother_occ_academic                  0\n",
      "mother_occ_service_manual            0\n",
      "mother_occ_technical_admin           0\n",
      "mother_occ_unskilled_other           0\n",
      "mother_qualification_basic           0\n",
      "mother_qualification_higher          0\n",
      "mother_qualification_secondary       0\n",
      "nationality_africa                   0\n",
      "nationality_asia                     0\n",
      "nationality_europe                   0\n",
      "nationality_north_america            0\n",
      "nationality_south_america            0\n",
      "no_evaluation_total                  0\n",
      "partnered                            0\n",
      "prediction                           0\n",
      "prev_partnered                       0\n",
      "prevqual_basic                       0\n",
      "prevqual_higher                      0\n",
      "prevqual_secondary                   0\n",
      "single                               0\n",
      "studyfield_arts&comm                 0\n",
      "studyfield_business_social           0\n",
      "studyfield_stem                      0\n",
      "success_rate                       180\n",
      "total_enrolled                       0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 180\n"
     ]
    }
   ],
   "source": [
    "num_cols = df.select_dtypes(include=[np.number]).columns.difference([\"involves_counterfeit\"])\n",
    "\n",
    "print(df[num_cols].isna().sum())\n",
    "\n",
    "print(\"\\nTotal missing values:\", df[num_cols].isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892433d9",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "The check revealed 180 missing values in the success_rate column. These likely correspond to students who did not complete their studies, resulting in missing academic performance data for those cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "51788094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "success_rate    180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()[df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d005e",
   "metadata": {},
   "source": [
    "### Filling Missing Success Rates\n",
    "\n",
    "Missing values in the success_rate column are filled with 0. This approach retains students who did not complete their studies, allowing the model to learn from these cases instead of excluding them from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "08a0b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"success_rate\"] = df[\"success_rate\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939da034",
   "metadata": {},
   "source": [
    "### Duplicate Check and Removal\n",
    "\n",
    "The datast is checked for duplicat rows to ensure data integrity. Any duplicated founrd are displayed, then removed, and the index is reset. Thes step prevents redundant records from biasing the model or affecting statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7e4ebbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 0\n",
      "After dropping duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "duplicates_count = df.duplicated().sum()\n",
    "print(\"Number of duplicates:\", duplicates_count)\n",
    "\n",
    "if duplicates_count > 0:\n",
    "    display(df[df.duplicated()])\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print(\"After dropping duplicates:\", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3871ae",
   "metadata": {},
   "source": [
    "### Feature and Target Preparation\n",
    "\n",
    "The dataset is split into features (X) and target (prediction). The target values are label-encoded into numerical form using LabelEncoder and then one-hot encoded for use in a neural network. The variable categories stores the class labels (Dropout, Enrolled, Graduate) for reference. This code for the correlation matrix was used from the teaching notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4ec6e0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('prediction', axis=1)\n",
    "\n",
    "y_temp = df['prediction']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_temp)\n",
    "\n",
    "y = tf.keras.utils.to_categorical(y_enc)\n",
    "\n",
    "categories = list(le.classes_)\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5b685",
   "metadata": {},
   "source": [
    "### Correlation Analysis\n",
    "\n",
    "A correlation matrix was computed to examine how each variable relates to the prediction (student outcome). The strongest positive correlations were found with success_rate (0.69), avg_grade (0.55), and Tuition fees up to date (0.41), indicating these factors are highly associated with academic success. Negative correlations, such as Debtor (-0.24) and Age at enrollment (-0.24), suggest that financial or demographic factors may increase the likelihood of dropout. This code for the correlation matrix was used from the teaching notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3da55101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction                         1.00\n",
       "success_rate                       0.69\n",
       "avg_grade                          0.55\n",
       "Tuition fees up to date            0.41\n",
       "Scholarship holder                 0.30\n",
       "admission_general                  0.24\n",
       "total_enrolled                     0.17\n",
       "prevqual_secondary                 0.15\n",
       "studyfield_arts&comm               0.14\n",
       "Admission grade                    0.12\n",
       "Displaced                          0.11\n",
       "single                             0.11\n",
       "Previous qualification (grade)     0.10\n",
       "is_daytime                         0.08\n",
       "father_occ_service_manual          0.07\n",
       "father_qualification_basic         0.06\n",
       "GDP                                0.04\n",
       "mother_qualification_secondary     0.04\n",
       "mother_occ_service_manual          0.03\n",
       "mother_occ_technical_admin         0.03\n",
       "nationality_africa                 0.02\n",
       "mother_qualification_basic         0.01\n",
       "Unemployment rate                  0.01\n",
       "International                      0.00\n",
       "father_qualification_secondary     0.00\n",
       "father_occ_technical_admin        -0.00\n",
       "nationality_asia                  -0.00\n",
       "nationality_north_america         -0.01\n",
       "nationality_europe                -0.01\n",
       "Educational special needs         -0.01\n",
       "mother_qualification_higher       -0.01\n",
       "nationality_south_america         -0.01\n",
       "mother_occ_academic               -0.03\n",
       "Inflation rate                    -0.03\n",
       "father_occ_academic               -0.03\n",
       "father_qualification_higher       -0.03\n",
       "mother_occ_unskilled_other        -0.04\n",
       "admission_transfer                -0.04\n",
       "father_occ_unskilled_other        -0.05\n",
       "prev_partnered                    -0.05\n",
       "prevqual_higher                   -0.07\n",
       "high_priority                     -0.07\n",
       "studyfield_business_social        -0.07\n",
       "studyfield_stem                   -0.08\n",
       "partnered                         -0.09\n",
       "no_evaluation_total               -0.09\n",
       "prevqual_basic                    -0.15\n",
       "Gender                            -0.23\n",
       "admission_special/international   -0.24\n",
       "Debtor                            -0.24\n",
       "Age at enrollment                 -0.24\n",
       "Name: prediction, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = df.corr()['prediction']\n",
    "corr_matrix.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68daca",
   "metadata": {},
   "source": [
    "### Chi-Square Feature Importance Results\n",
    "\n",
    "The Chi-Square test identified the most influential features for predicting student outcomes. The highest-scoring variables are avg_grade (3016.44), success_rate (820.68), and Age at enrollment (715.98), indicating that academic performance and demographic factors play key roles in determining success. Features with lower scores, such as nationality_europe or father_occ_technical_admin, have minimal statistical impact on the target variable. This code for the correlation matrix was used from the teaching notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3b036629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>avg_grade</td>\n",
       "      <td>3016.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>success_rate</td>\n",
       "      <td>820.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Age at enrollment</td>\n",
       "      <td>715.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scholarship holder</td>\n",
       "      <td>308.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Debtor</td>\n",
       "      <td>229.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>total_enrolled</td>\n",
       "      <td>226.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>no_evaluation_total</td>\n",
       "      <td>224.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>admission_special/international</td>\n",
       "      <td>203.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender</td>\n",
       "      <td>151.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admission grade</td>\n",
       "      <td>112.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>prevqual_basic</td>\n",
       "      <td>109.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuition fees up to date</td>\n",
       "      <td>98.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>admission_general</td>\n",
       "      <td>97.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Previous qualification (grade)</td>\n",
       "      <td>72.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>studyfield_arts&amp;comm</td>\n",
       "      <td>65.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>studyfield_stem</td>\n",
       "      <td>48.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>partnered</td>\n",
       "      <td>41.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>prevqual_higher</td>\n",
       "      <td>38.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Displaced</td>\n",
       "      <td>26.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>admission_transfer</td>\n",
       "      <td>21.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GDP</td>\n",
       "      <td>16.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>prevqual_secondary</td>\n",
       "      <td>16.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>father_occ_unskilled_other</td>\n",
       "      <td>15.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>father_occ_service_manual</td>\n",
       "      <td>14.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mother_occ_unskilled_other</td>\n",
       "      <td>13.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>studyfield_business_social</td>\n",
       "      <td>13.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mother_qualification_higher</td>\n",
       "      <td>13.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>father_qualification_higher</td>\n",
       "      <td>11.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>prev_partnered</td>\n",
       "      <td>11.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>father_occ_academic</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>mother_occ_academic</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>8.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mother_qualification_secondary</td>\n",
       "      <td>7.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mother_occ_technical_admin</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Inflation rate</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>single</td>\n",
       "      <td>6.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>father_qualification_basic</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>nationality_asia</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>mother_occ_service_manual</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>high_priority</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>is_daytime</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>nationality_africa</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mother_qualification_basic</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>father_qualification_secondary</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nationality_south_america</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Educational special needs</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nationality_north_america</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>father_occ_technical_admin</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nationality_europe</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Features   Score\n",
       "46                        avg_grade 3016.44\n",
       "47                     success_rate  820.68\n",
       "8                 Age at enrollment  715.98\n",
       "7                Scholarship holder  308.11\n",
       "4                            Debtor  229.85\n",
       "48                   total_enrolled  226.82\n",
       "49              no_evaluation_total  224.81\n",
       "18  admission_special/international  203.51\n",
       "6                            Gender  151.22\n",
       "1                   Admission grade  112.25\n",
       "24                   prevqual_basic  109.79\n",
       "5           Tuition fees up to date   98.29\n",
       "16                admission_general   97.39\n",
       "0    Previous qualification (grade)   72.35\n",
       "22             studyfield_arts&comm   65.38\n",
       "20                  studyfield_stem   48.96\n",
       "14                        partnered   41.24\n",
       "26                  prevqual_higher   38.28\n",
       "2                         Displaced   26.08\n",
       "17               admission_transfer   21.16\n",
       "12                              GDP   16.83\n",
       "25               prevqual_secondary   16.49\n",
       "45       father_occ_unskilled_other   15.64\n",
       "44        father_occ_service_manual   14.51\n",
       "41       mother_occ_unskilled_other   13.71\n",
       "21       studyfield_business_social   13.70\n",
       "34      mother_qualification_higher   13.39\n",
       "37      father_qualification_higher   11.77\n",
       "15                   prev_partnered   11.30\n",
       "42              father_occ_academic    9.25\n",
       "38              mother_occ_academic    8.11\n",
       "10                Unemployment rate    8.04\n",
       "33   mother_qualification_secondary    7.51\n",
       "39       mother_occ_technical_admin    7.25\n",
       "11                   Inflation rate    7.24\n",
       "13                           single    6.57\n",
       "35       father_qualification_basic    5.58\n",
       "31                 nationality_asia    4.57\n",
       "40        mother_occ_service_manual    3.71\n",
       "19                    high_priority    3.25\n",
       "23                       is_daytime    3.14\n",
       "28               nationality_africa    2.68\n",
       "32       mother_qualification_basic    2.19\n",
       "36   father_qualification_secondary    1.31\n",
       "9                     International    1.25\n",
       "29        nationality_south_america    0.74\n",
       "3         Educational special needs    0.63\n",
       "30        nationality_north_america    0.56\n",
       "43       father_occ_technical_admin    0.05\n",
       "27               nationality_europe    0.01"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat = X.astype(int)\n",
    "X_cat = X_cat.clip(lower=0)\n",
    "\n",
    "chi_2_features = SelectKBest(chi2, k=len(X_cat.columns))\n",
    "\n",
    "best_features = chi_2_features.fit(X_cat,y.astype(int))\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "df_features = pd.DataFrame(best_features.scores_)\n",
    "df_columns = pd.DataFrame(X_cat.columns)\n",
    "f_scores = pd.concat([df_columns,df_features],axis=1)\n",
    "f_scores.columns = ['Features','Score']\n",
    "f_scores.sort_values(by='Score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ad102",
   "metadata": {},
   "source": [
    "After performing correlation analysis, the Chi-Square test, and an additional like Phik correlation test, no variables were removed from the dataset. Several combinations were tested to eliminate less relevant features, but in every case, the model’s performance decreased compared to using the full feature set. Therefore, all variables were retained for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c66eda",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "\n",
    "The dataset was split into 70% training, 15% validation, and 15% testing using train_test_split().\n",
    "This ensures that the model is trained, tuned, and evaluated on separate data subsets for reliable performance.\n",
    "This code for the correlation matrix was used from the teaching notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e66842fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810dfbe9",
   "metadata": {},
   "source": [
    "### Keras Tuner\n",
    "\n",
    "Several Keras Tuner runs were performed with different configurations, including up to 25 max_trials and 2 executions per trial.\n",
    "Across all tuning sessions, the best result achieved a validation accuracy of 0.7439 (≈74.4%), indicating the most effective hyperparameter combination.\n",
    "This optimized setup was later used to build and train the final tuned neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79dfe433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 04m 12s]\n",
      "val_accuracy: 0.7364457845687866\n",
      "\n",
      "Best val_accuracy So Far: 0.7484939694404602\n",
      "Total elapsed time: 00h 44m 36s\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(layers.BatchNormalization(input_shape=(len(X.columns),)),)\n",
    "    \n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            units=hp.Int(f\"units_0\", min_value=4, max_value=96, step=4),\n",
    "            activation=hp.Choice(\"activation\", [\"relu\"]),\n",
    "            kernel_regularizer=keras.regularizers.l1(hp.Float(\"l1\", min_value=0.025, max_value=0.35, sampling=\"log\"))\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(\n",
    "            hp.Float(\"rate\", min_value=0.1, max_value=0.5, step=0.025)\n",
    "            ))\n",
    "\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=hp.Int(f\"units_{i + 1}\", min_value=8, max_value=96, step=4),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    model.add(layers.Dense(len(categories), activation=\"softmax\"))\n",
    "\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-1, sampling=\"log\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy', metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"optimizations1\",\n",
    "    project_name=\"classification1test\",\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=250, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "837c1b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in optimizations1\\classification1test\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units_0: 56\n",
      "activation: relu\n",
      "l1: 0.0786154200423072\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 52\n",
      "lr: 0.01025743164634268\n",
      "rate: 0.25\n",
      "units_2: 84\n",
      "units_3: 92\n",
      "Score: 0.7484939694404602\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units_0: 8\n",
      "activation: relu\n",
      "l1: 0.032775858355832944\n",
      "dropout: True\n",
      "num_layers: 3\n",
      "units_1: 96\n",
      "lr: 0.0008850590237043235\n",
      "rate: 0.2\n",
      "units_2: 92\n",
      "units_3: 16\n",
      "Score: 0.7462349534034729\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units_0: 64\n",
      "activation: relu\n",
      "l1: 0.14404386359839785\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 92\n",
      "lr: 0.0005495772755430749\n",
      "rate: 0.1\n",
      "units_2: 8\n",
      "Score: 0.7439759075641632\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units_0: 84\n",
      "activation: relu\n",
      "l1: 0.18829543465447462\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 24\n",
      "lr: 0.0008791338401733138\n",
      "rate: 0.5\n",
      "units_2: 32\n",
      "units_3: 92\n",
      "Score: 0.7364457845687866\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units_0: 76\n",
      "activation: relu\n",
      "l1: 0.030030643841972265\n",
      "dropout: True\n",
      "num_layers: 3\n",
      "units_1: 12\n",
      "lr: 3.933578568657208e-05\n",
      "rate: 0.375\n",
      "units_2: 80\n",
      "units_3: 8\n",
      "Score: 0.7281626760959625\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units_0: 84\n",
      "activation: relu\n",
      "l1: 0.09277436194925\n",
      "dropout: False\n",
      "num_layers: 2\n",
      "units_1: 48\n",
      "lr: 8.236127782483122e-05\n",
      "rate: 0.275\n",
      "units_2: 16\n",
      "units_3: 32\n",
      "Score: 0.7281626760959625\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units_0: 80\n",
      "activation: relu\n",
      "l1: 0.06506737046346531\n",
      "dropout: True\n",
      "num_layers: 1\n",
      "units_1: 72\n",
      "lr: 0.072305430326835\n",
      "rate: 0.25\n",
      "units_2: 8\n",
      "units_3: 84\n",
      "Score: 0.7259036302566528\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units_0: 36\n",
      "activation: relu\n",
      "l1: 0.13826368986509668\n",
      "dropout: False\n",
      "num_layers: 1\n",
      "units_1: 16\n",
      "lr: 0.0002866272044667064\n",
      "rate: 0.4\n",
      "units_2: 32\n",
      "units_3: 68\n",
      "Score: 0.7259036302566528\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "units_0: 76\n",
      "activation: relu\n",
      "l1: 0.09581597838029794\n",
      "dropout: False\n",
      "num_layers: 3\n",
      "units_1: 84\n",
      "lr: 0.07059356474578148\n",
      "rate: 0.42500000000000004\n",
      "units_2: 44\n",
      "units_3: 72\n",
      "Score: 0.6076807081699371\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units_0: 92\n",
      "activation: relu\n",
      "l1: 0.08953892517094426\n",
      "dropout: True\n",
      "num_layers: 2\n",
      "units_1: 72\n",
      "lr: 0.08602771881818747\n",
      "rate: 0.45000000000000007\n",
      "units_2: 36\n",
      "units_3: 96\n",
      "Score: 0.6031626462936401\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d08b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\Mani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,964</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,452</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │         \u001b[38;5;34m2,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m)             │         \u001b[38;5;34m2,964\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │         \u001b[38;5;34m4,452\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m255\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,727</span> (41.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,727\u001b[0m (41.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,627</span> (41.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,627\u001b[0m (41.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> (400.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m100\u001b[0m (400.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = tuner.get_best_models(num_models=1)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733c414a",
   "metadata": {},
   "source": [
    "### Model Architecture and Training Setup\n",
    "\n",
    "A Keras sequential neural network was built for multiclass classification with Batch Normalization, Dense ReLU layers using L1 regularization, a 0.1 Dropout layer, and a Softmax output.\n",
    "The model used the Adam optimizer (lr = 0.00055) and categorical cross-entropy loss, based on tuner-optimized parameters.\n",
    "Training included ModelCheckpoint, EarlyStopping, and ReduceLROnPlateau callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797e62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,964</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,452</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │         \u001b[38;5;34m2,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m)             │         \u001b[38;5;34m2,964\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │         \u001b[38;5;34m4,452\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m255\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,727</span> (41.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,727\u001b[0m (41.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,627</span> (41.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,627\u001b[0m (41.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> (400.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m100\u001b[0m (400.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "variable_amount = X_train.shape[1]\n",
    "\n",
    "mc = ModelCheckpoint(\"best_model_student2.keras\", monitor=\"val_loss\", mode=\"min\", save_best_only=True)\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
    "rlr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n",
    "callbacks_opt = [mc, es, rlr]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape=(variable_amount,)),\n",
    "    layers.Dense(56, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(0.0786154200423072)),\n",
    "    layers.Dense(52, activation=\"relu\"),\n",
    "    layers.Dense(84, activation=\"relu\"),\n",
    "    layers.Dense(len(categories), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "optimal_lr = 0.01025743164634268\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=optimal_lr),loss='categorical_crossentropy',metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c5800",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "The model was trained for up to 500 epochs using the training and validation sets.\n",
    "The training process included callbacks with ModelCheckpoint, EarlyStopping, and ReduceLROnPlateau so to save the best-performing model, stop training early to avoid overfitting and adjust the learning rate when validation loss stopped improving.\n",
    "This setup ensured stable convergence and optimized generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2d502953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6909 - loss: 4.0154 - val_accuracy: 0.6416 - val_loss: 1.3419 - learning_rate: 0.0103\n",
      "Epoch 2/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7313 - loss: 1.1482 - val_accuracy: 0.7093 - val_loss: 1.2442 - learning_rate: 0.0103\n",
      "Epoch 3/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 1.0946 - val_accuracy: 0.7244 - val_loss: 1.1436 - learning_rate: 0.0103\n",
      "Epoch 4/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 1.0685 - val_accuracy: 0.7214 - val_loss: 1.1183 - learning_rate: 0.0103\n",
      "Epoch 5/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 1.0473 - val_accuracy: 0.7169 - val_loss: 1.1273 - learning_rate: 0.0103\n",
      "Epoch 6/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7348 - loss: 1.0371 - val_accuracy: 0.7259 - val_loss: 1.0992 - learning_rate: 0.0103\n",
      "Epoch 7/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 1.0286 - val_accuracy: 0.7139 - val_loss: 1.1104 - learning_rate: 0.0103\n",
      "Epoch 8/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 1.0174 - val_accuracy: 0.7154 - val_loss: 1.0803 - learning_rate: 0.0103\n",
      "Epoch 9/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7393 - loss: 1.0140 - val_accuracy: 0.7289 - val_loss: 1.0887 - learning_rate: 0.0103\n",
      "Epoch 10/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7361 - loss: 1.0097 - val_accuracy: 0.7289 - val_loss: 1.0778 - learning_rate: 0.0103\n",
      "Epoch 11/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7358 - loss: 0.9998 - val_accuracy: 0.7304 - val_loss: 1.0512 - learning_rate: 0.0103\n",
      "Epoch 12/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.9919 - val_accuracy: 0.7259 - val_loss: 1.0398 - learning_rate: 0.0103\n",
      "Epoch 13/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.9860 - val_accuracy: 0.7319 - val_loss: 1.0348 - learning_rate: 0.0103\n",
      "Epoch 14/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.9859 - val_accuracy: 0.7229 - val_loss: 1.0216 - learning_rate: 0.0103\n",
      "Epoch 15/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.9776 - val_accuracy: 0.7289 - val_loss: 1.0179 - learning_rate: 0.0103\n",
      "Epoch 16/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 0.9766 - val_accuracy: 0.7289 - val_loss: 1.0063 - learning_rate: 0.0103\n",
      "Epoch 17/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7406 - loss: 0.9706 - val_accuracy: 0.7304 - val_loss: 1.0070 - learning_rate: 0.0103\n",
      "Epoch 18/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.9706 - val_accuracy: 0.7289 - val_loss: 1.0128 - learning_rate: 0.0103\n",
      "Epoch 19/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7422 - loss: 0.9715 - val_accuracy: 0.7349 - val_loss: 0.9997 - learning_rate: 0.0103\n",
      "Epoch 20/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.9711 - val_accuracy: 0.7229 - val_loss: 1.0045 - learning_rate: 0.0103\n",
      "Epoch 21/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7455 - loss: 0.9731 - val_accuracy: 0.7380 - val_loss: 1.0073 - learning_rate: 0.0103\n",
      "Epoch 22/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7452 - loss: 0.9678 - val_accuracy: 0.7349 - val_loss: 1.0064 - learning_rate: 0.0103\n",
      "Epoch 23/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.9685 - val_accuracy: 0.7349 - val_loss: 0.9988 - learning_rate: 0.0103\n",
      "Epoch 24/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.9637 - val_accuracy: 0.7229 - val_loss: 1.0040 - learning_rate: 0.0103\n",
      "Epoch 25/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7442 - loss: 0.9641 - val_accuracy: 0.7229 - val_loss: 1.0089 - learning_rate: 0.0103\n",
      "Epoch 26/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7406 - loss: 0.9641 - val_accuracy: 0.7229 - val_loss: 1.0121 - learning_rate: 0.0103\n",
      "Epoch 27/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.9655 - val_accuracy: 0.7184 - val_loss: 1.0016 - learning_rate: 0.0103\n",
      "Epoch 28/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7406 - loss: 0.9685 - val_accuracy: 0.7199 - val_loss: 1.0067 - learning_rate: 0.0103\n",
      "Epoch 29/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.9706 - val_accuracy: 0.7259 - val_loss: 0.9920 - learning_rate: 0.0103\n",
      "Epoch 30/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7416 - loss: 0.9645 - val_accuracy: 0.7349 - val_loss: 0.9821 - learning_rate: 0.0103\n",
      "Epoch 31/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7435 - loss: 0.9602 - val_accuracy: 0.7274 - val_loss: 0.9830 - learning_rate: 0.0103\n",
      "Epoch 32/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7439 - loss: 0.9576 - val_accuracy: 0.7274 - val_loss: 0.9926 - learning_rate: 0.0103\n",
      "Epoch 33/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.9591 - val_accuracy: 0.7274 - val_loss: 0.9972 - learning_rate: 0.0103\n",
      "Epoch 34/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7435 - loss: 0.9571 - val_accuracy: 0.7304 - val_loss: 0.9745 - learning_rate: 0.0103\n",
      "Epoch 35/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7464 - loss: 0.9606 - val_accuracy: 0.7244 - val_loss: 1.0041 - learning_rate: 0.0103\n",
      "Epoch 36/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7393 - loss: 0.9631 - val_accuracy: 0.7334 - val_loss: 0.9755 - learning_rate: 0.0103\n",
      "Epoch 37/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.9572 - val_accuracy: 0.7184 - val_loss: 0.9711 - learning_rate: 0.0103\n",
      "Epoch 38/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 0.9545 - val_accuracy: 0.7244 - val_loss: 0.9788 - learning_rate: 0.0103\n",
      "Epoch 39/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.9605 - val_accuracy: 0.7274 - val_loss: 0.9729 - learning_rate: 0.0103\n",
      "Epoch 40/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7422 - loss: 0.9563 - val_accuracy: 0.7214 - val_loss: 0.9878 - learning_rate: 0.0103\n",
      "Epoch 41/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7439 - loss: 0.9556 - val_accuracy: 0.7214 - val_loss: 0.9775 - learning_rate: 0.0103\n",
      "Epoch 42/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.9598 - val_accuracy: 0.7319 - val_loss: 0.9737 - learning_rate: 0.0103\n",
      "Epoch 43/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.9555 - val_accuracy: 0.7244 - val_loss: 0.9732 - learning_rate: 0.0103\n",
      "Epoch 44/2000\n",
      "\u001b[1m79/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7629 - loss: 0.9471\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00512871565297246.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 0.9602 - val_accuracy: 0.7123 - val_loss: 1.0099 - learning_rate: 0.0103\n",
      "Epoch 45/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7452 - loss: 0.8254 - val_accuracy: 0.7139 - val_loss: 0.8157 - learning_rate: 0.0051\n",
      "Epoch 46/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7468 - loss: 0.8031 - val_accuracy: 0.7139 - val_loss: 0.8141 - learning_rate: 0.0051\n",
      "Epoch 47/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7474 - loss: 0.8048 - val_accuracy: 0.7304 - val_loss: 0.8144 - learning_rate: 0.0051\n",
      "Epoch 48/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7471 - loss: 0.8030 - val_accuracy: 0.7364 - val_loss: 0.8131 - learning_rate: 0.0051\n",
      "Epoch 49/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7490 - loss: 0.8005 - val_accuracy: 0.7349 - val_loss: 0.8180 - learning_rate: 0.0051\n",
      "Epoch 50/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7487 - loss: 0.8043 - val_accuracy: 0.7334 - val_loss: 0.8136 - learning_rate: 0.0051\n",
      "Epoch 51/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7516 - loss: 0.8024 - val_accuracy: 0.7395 - val_loss: 0.8113 - learning_rate: 0.0051\n",
      "Epoch 52/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7510 - loss: 0.8018 - val_accuracy: 0.7319 - val_loss: 0.8114 - learning_rate: 0.0051\n",
      "Epoch 53/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7552 - loss: 0.8000 - val_accuracy: 0.7334 - val_loss: 0.8051 - learning_rate: 0.0051\n",
      "Epoch 54/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7503 - loss: 0.7990 - val_accuracy: 0.7364 - val_loss: 0.8072 - learning_rate: 0.0051\n",
      "Epoch 55/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7523 - loss: 0.8012 - val_accuracy: 0.7380 - val_loss: 0.8101 - learning_rate: 0.0051\n",
      "Epoch 56/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7519 - loss: 0.8007 - val_accuracy: 0.7319 - val_loss: 0.8222 - learning_rate: 0.0051\n",
      "Epoch 57/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7571 - loss: 0.8012 - val_accuracy: 0.7319 - val_loss: 0.8171 - learning_rate: 0.0051\n",
      "Epoch 58/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7548 - loss: 0.7984 - val_accuracy: 0.7289 - val_loss: 0.8190 - learning_rate: 0.0051\n",
      "Epoch 59/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7526 - loss: 0.7969 - val_accuracy: 0.7289 - val_loss: 0.8147 - learning_rate: 0.0051\n",
      "Epoch 60/2000\n",
      "\u001b[1m86/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7747 - loss: 0.7839\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00256435782648623.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.7965 - val_accuracy: 0.7289 - val_loss: 0.8129 - learning_rate: 0.0051\n",
      "Epoch 61/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7523 - loss: 0.7282 - val_accuracy: 0.7319 - val_loss: 0.7527 - learning_rate: 0.0026\n",
      "Epoch 62/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7526 - loss: 0.7173 - val_accuracy: 0.7274 - val_loss: 0.7557 - learning_rate: 0.0026\n",
      "Epoch 63/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7526 - loss: 0.7162 - val_accuracy: 0.7214 - val_loss: 0.7557 - learning_rate: 0.0026\n",
      "Epoch 64/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7539 - loss: 0.7151 - val_accuracy: 0.7289 - val_loss: 0.7471 - learning_rate: 0.0026\n",
      "Epoch 65/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7542 - loss: 0.7140 - val_accuracy: 0.7259 - val_loss: 0.7497 - learning_rate: 0.0026\n",
      "Epoch 66/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7513 - loss: 0.7130 - val_accuracy: 0.7289 - val_loss: 0.7450 - learning_rate: 0.0026\n",
      "Epoch 67/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7516 - loss: 0.7122 - val_accuracy: 0.7259 - val_loss: 0.7454 - learning_rate: 0.0026\n",
      "Epoch 68/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7529 - loss: 0.7116 - val_accuracy: 0.7244 - val_loss: 0.7427 - learning_rate: 0.0026\n",
      "Epoch 69/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7513 - loss: 0.7104 - val_accuracy: 0.7274 - val_loss: 0.7443 - learning_rate: 0.0026\n",
      "Epoch 70/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7545 - loss: 0.7104 - val_accuracy: 0.7289 - val_loss: 0.7488 - learning_rate: 0.0026\n",
      "Epoch 71/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7555 - loss: 0.7111 - val_accuracy: 0.7274 - val_loss: 0.7487 - learning_rate: 0.0026\n",
      "Epoch 72/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7571 - loss: 0.7096 - val_accuracy: 0.7289 - val_loss: 0.7505 - learning_rate: 0.0026\n",
      "Epoch 73/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.7097 - val_accuracy: 0.7274 - val_loss: 0.7451 - learning_rate: 0.0026\n",
      "Epoch 74/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.7103 - val_accuracy: 0.7289 - val_loss: 0.7472 - learning_rate: 0.0026\n",
      "Epoch 75/2000\n",
      "\u001b[1m86/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7720 - loss: 0.6927\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.001282178913243115.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7555 - loss: 0.7092 - val_accuracy: 0.7289 - val_loss: 0.7494 - learning_rate: 0.0026\n",
      "Epoch 76/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7545 - loss: 0.6694 - val_accuracy: 0.7259 - val_loss: 0.6993 - learning_rate: 0.0013\n",
      "Epoch 77/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7558 - loss: 0.6635 - val_accuracy: 0.7244 - val_loss: 0.7034 - learning_rate: 0.0013\n",
      "Epoch 78/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7552 - loss: 0.6629 - val_accuracy: 0.7259 - val_loss: 0.6994 - learning_rate: 0.0013\n",
      "Epoch 79/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.6628 - val_accuracy: 0.7304 - val_loss: 0.6972 - learning_rate: 0.0013\n",
      "Epoch 80/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7581 - loss: 0.6629 - val_accuracy: 0.7289 - val_loss: 0.6995 - learning_rate: 0.0013\n",
      "Epoch 81/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7581 - loss: 0.6632 - val_accuracy: 0.7349 - val_loss: 0.6931 - learning_rate: 0.0013\n",
      "Epoch 82/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.6630 - val_accuracy: 0.7349 - val_loss: 0.6927 - learning_rate: 0.0013\n",
      "Epoch 83/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.6625 - val_accuracy: 0.7364 - val_loss: 0.6933 - learning_rate: 0.0013\n",
      "Epoch 84/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7571 - loss: 0.6623 - val_accuracy: 0.7349 - val_loss: 0.6931 - learning_rate: 0.0013\n",
      "Epoch 85/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7565 - loss: 0.6613 - val_accuracy: 0.7319 - val_loss: 0.6914 - learning_rate: 0.0013\n",
      "Epoch 86/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7578 - loss: 0.6610 - val_accuracy: 0.7349 - val_loss: 0.6902 - learning_rate: 0.0013\n",
      "Epoch 87/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.6603 - val_accuracy: 0.7364 - val_loss: 0.6924 - learning_rate: 0.0013\n",
      "Epoch 88/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7558 - loss: 0.6599 - val_accuracy: 0.7364 - val_loss: 0.6894 - learning_rate: 0.0013\n",
      "Epoch 89/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7539 - loss: 0.6593 - val_accuracy: 0.7395 - val_loss: 0.6885 - learning_rate: 0.0013\n",
      "Epoch 90/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7548 - loss: 0.6587 - val_accuracy: 0.7395 - val_loss: 0.6908 - learning_rate: 0.0013\n",
      "Epoch 91/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7555 - loss: 0.6590 - val_accuracy: 0.7364 - val_loss: 0.6891 - learning_rate: 0.0013\n",
      "Epoch 92/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7539 - loss: 0.6580 - val_accuracy: 0.7380 - val_loss: 0.6897 - learning_rate: 0.0013\n",
      "Epoch 93/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7532 - loss: 0.6573 - val_accuracy: 0.7395 - val_loss: 0.6874 - learning_rate: 0.0013\n",
      "Epoch 94/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7529 - loss: 0.6571 - val_accuracy: 0.7395 - val_loss: 0.6890 - learning_rate: 0.0013\n",
      "Epoch 95/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7532 - loss: 0.6570 - val_accuracy: 0.7425 - val_loss: 0.6866 - learning_rate: 0.0013\n",
      "Epoch 96/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7542 - loss: 0.6568 - val_accuracy: 0.7410 - val_loss: 0.6851 - learning_rate: 0.0013\n",
      "Epoch 97/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7539 - loss: 0.6564 - val_accuracy: 0.7380 - val_loss: 0.6894 - learning_rate: 0.0013\n",
      "Epoch 98/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7536 - loss: 0.6562 - val_accuracy: 0.7410 - val_loss: 0.6868 - learning_rate: 0.0013\n",
      "Epoch 99/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7548 - loss: 0.6565 - val_accuracy: 0.7410 - val_loss: 0.6857 - learning_rate: 0.0013\n",
      "Epoch 100/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7542 - loss: 0.6558 - val_accuracy: 0.7395 - val_loss: 0.6865 - learning_rate: 0.0013\n",
      "Epoch 101/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7536 - loss: 0.6557 - val_accuracy: 0.7410 - val_loss: 0.6844 - learning_rate: 0.0013\n",
      "Epoch 102/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7539 - loss: 0.6560 - val_accuracy: 0.7425 - val_loss: 0.6843 - learning_rate: 0.0013\n",
      "Epoch 103/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7545 - loss: 0.6563 - val_accuracy: 0.7425 - val_loss: 0.6854 - learning_rate: 0.0013\n",
      "Epoch 104/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7555 - loss: 0.6562 - val_accuracy: 0.7410 - val_loss: 0.6858 - learning_rate: 0.0013\n",
      "Epoch 105/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7542 - loss: 0.6557 - val_accuracy: 0.7425 - val_loss: 0.6865 - learning_rate: 0.0013\n",
      "Epoch 106/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7542 - loss: 0.6558 - val_accuracy: 0.7380 - val_loss: 0.6839 - learning_rate: 0.0013\n",
      "Epoch 107/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7558 - loss: 0.6556 - val_accuracy: 0.7395 - val_loss: 0.6852 - learning_rate: 0.0013\n",
      "Epoch 108/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.6560 - val_accuracy: 0.7410 - val_loss: 0.6852 - learning_rate: 0.0013\n",
      "Epoch 109/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.6555 - val_accuracy: 0.7410 - val_loss: 0.6822 - learning_rate: 0.0013\n",
      "Epoch 110/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7555 - loss: 0.6549 - val_accuracy: 0.7395 - val_loss: 0.6850 - learning_rate: 0.0013\n",
      "Epoch 111/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7561 - loss: 0.6552 - val_accuracy: 0.7364 - val_loss: 0.6856 - learning_rate: 0.0013\n",
      "Epoch 112/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7581 - loss: 0.6550 - val_accuracy: 0.7380 - val_loss: 0.6831 - learning_rate: 0.0013\n",
      "Epoch 113/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7565 - loss: 0.6552 - val_accuracy: 0.7395 - val_loss: 0.6853 - learning_rate: 0.0013\n",
      "Epoch 114/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7565 - loss: 0.6550 - val_accuracy: 0.7380 - val_loss: 0.6852 - learning_rate: 0.0013\n",
      "Epoch 115/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.6551 - val_accuracy: 0.7380 - val_loss: 0.6849 - learning_rate: 0.0013\n",
      "Epoch 116/2000\n",
      "\u001b[1m89/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7748 - loss: 0.6383\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 0.0006410894566215575.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.6550 - val_accuracy: 0.7364 - val_loss: 0.6858 - learning_rate: 0.0013\n",
      "Epoch 117/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6359 - val_accuracy: 0.7425 - val_loss: 0.6578 - learning_rate: 6.4109e-04\n",
      "Epoch 118/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7574 - loss: 0.6330 - val_accuracy: 0.7470 - val_loss: 0.6574 - learning_rate: 6.4109e-04\n",
      "Epoch 119/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7587 - loss: 0.6325 - val_accuracy: 0.7470 - val_loss: 0.6581 - learning_rate: 6.4109e-04\n",
      "Epoch 120/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.6324 - val_accuracy: 0.7410 - val_loss: 0.6587 - learning_rate: 6.4109e-04\n",
      "Epoch 121/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.6324 - val_accuracy: 0.7425 - val_loss: 0.6599 - learning_rate: 6.4109e-04\n",
      "Epoch 122/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.6322 - val_accuracy: 0.7410 - val_loss: 0.6595 - learning_rate: 6.4109e-04\n",
      "Epoch 123/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7578 - loss: 0.6321 - val_accuracy: 0.7410 - val_loss: 0.6606 - learning_rate: 6.4109e-04\n",
      "Epoch 124/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7581 - loss: 0.6319 - val_accuracy: 0.7425 - val_loss: 0.6604 - learning_rate: 6.4109e-04\n",
      "Epoch 125/2000\n",
      "\u001b[1m86/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7692 - loss: 0.6167\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 0.00032054472831077874.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.6319 - val_accuracy: 0.7410 - val_loss: 0.6602 - learning_rate: 6.4109e-04\n",
      "Epoch 126/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7555 - loss: 0.6223 - val_accuracy: 0.7410 - val_loss: 0.6440 - learning_rate: 3.2054e-04\n",
      "Epoch 127/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.6205 - val_accuracy: 0.7425 - val_loss: 0.6441 - learning_rate: 3.2054e-04\n",
      "Epoch 128/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.6203 - val_accuracy: 0.7425 - val_loss: 0.6445 - learning_rate: 3.2054e-04\n",
      "Epoch 129/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7584 - loss: 0.6200 - val_accuracy: 0.7440 - val_loss: 0.6448 - learning_rate: 3.2054e-04\n",
      "Epoch 130/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7587 - loss: 0.6201 - val_accuracy: 0.7425 - val_loss: 0.6447 - learning_rate: 3.2054e-04\n",
      "Epoch 131/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7581 - loss: 0.6198 - val_accuracy: 0.7425 - val_loss: 0.6448 - learning_rate: 3.2054e-04\n",
      "Epoch 132/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.6195 - val_accuracy: 0.7425 - val_loss: 0.6451 - learning_rate: 3.2054e-04\n",
      "Epoch 133/2000\n",
      "\u001b[1m91/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7694 - loss: 0.6048\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 0.00016027236415538937.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.6197 - val_accuracy: 0.7425 - val_loss: 0.6448 - learning_rate: 3.2054e-04\n",
      "Epoch 134/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7565 - loss: 0.6140 - val_accuracy: 0.7425 - val_loss: 0.6385 - learning_rate: 1.6027e-04\n",
      "Epoch 135/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7574 - loss: 0.6123 - val_accuracy: 0.7425 - val_loss: 0.6385 - learning_rate: 1.6027e-04\n",
      "Epoch 136/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.6121 - val_accuracy: 0.7425 - val_loss: 0.6383 - learning_rate: 1.6027e-04\n",
      "Epoch 137/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7571 - loss: 0.6120 - val_accuracy: 0.7425 - val_loss: 0.6383 - learning_rate: 1.6027e-04\n",
      "Epoch 138/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.6119 - val_accuracy: 0.7425 - val_loss: 0.6386 - learning_rate: 1.6027e-04\n",
      "Epoch 139/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7574 - loss: 0.6118 - val_accuracy: 0.7440 - val_loss: 0.6383 - learning_rate: 1.6027e-04\n",
      "Epoch 140/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7578 - loss: 0.6117 - val_accuracy: 0.7440 - val_loss: 0.6381 - learning_rate: 1.6027e-04\n",
      "Epoch 141/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7574 - loss: 0.6116 - val_accuracy: 0.7440 - val_loss: 0.6381 - learning_rate: 1.6027e-04\n",
      "Epoch 142/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7578 - loss: 0.6116 - val_accuracy: 0.7440 - val_loss: 0.6381 - learning_rate: 1.6027e-04\n",
      "Epoch 143/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.6116 - val_accuracy: 0.7440 - val_loss: 0.6382 - learning_rate: 1.6027e-04\n",
      "Epoch 144/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.6115 - val_accuracy: 0.7440 - val_loss: 0.6384 - learning_rate: 1.6027e-04\n",
      "Epoch 145/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7574 - loss: 0.6115 - val_accuracy: 0.7440 - val_loss: 0.6382 - learning_rate: 1.6027e-04\n",
      "Epoch 146/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.6114 - val_accuracy: 0.7440 - val_loss: 0.6381 - learning_rate: 1.6027e-04\n",
      "Epoch 147/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.6114 - val_accuracy: 0.7440 - val_loss: 0.6380 - learning_rate: 1.6027e-04\n",
      "Epoch 148/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.6113 - val_accuracy: 0.7455 - val_loss: 0.6383 - learning_rate: 1.6027e-04\n",
      "Epoch 149/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7571 - loss: 0.6113 - val_accuracy: 0.7455 - val_loss: 0.6382 - learning_rate: 1.6027e-04\n",
      "Epoch 150/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7561 - loss: 0.6112 - val_accuracy: 0.7455 - val_loss: 0.6383 - learning_rate: 1.6027e-04\n",
      "Epoch 151/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7561 - loss: 0.6111 - val_accuracy: 0.7455 - val_loss: 0.6383 - learning_rate: 1.6027e-04\n",
      "Epoch 152/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7561 - loss: 0.6111 - val_accuracy: 0.7455 - val_loss: 0.6380 - learning_rate: 1.6027e-04\n",
      "Epoch 153/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.6110 - val_accuracy: 0.7470 - val_loss: 0.6379 - learning_rate: 1.6027e-04\n",
      "Epoch 154/2000\n",
      "\u001b[1m86/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7663 - loss: 0.5958\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 8.013618207769468e-05.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7565 - loss: 0.6110 - val_accuracy: 0.7470 - val_loss: 0.6380 - learning_rate: 1.6027e-04\n",
      "Epoch 155/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7590 - loss: 0.6076 - val_accuracy: 0.7440 - val_loss: 0.6347 - learning_rate: 8.0136e-05\n",
      "Epoch 156/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6068 - val_accuracy: 0.7440 - val_loss: 0.6347 - learning_rate: 8.0136e-05\n",
      "Epoch 157/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6067 - val_accuracy: 0.7440 - val_loss: 0.6344 - learning_rate: 8.0136e-05\n",
      "Epoch 158/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6067 - val_accuracy: 0.7440 - val_loss: 0.6343 - learning_rate: 8.0136e-05\n",
      "Epoch 159/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7594 - loss: 0.6066 - val_accuracy: 0.7440 - val_loss: 0.6344 - learning_rate: 8.0136e-05\n",
      "Epoch 160/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7594 - loss: 0.6066 - val_accuracy: 0.7440 - val_loss: 0.6344 - learning_rate: 8.0136e-05\n",
      "Epoch 161/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7594 - loss: 0.6066 - val_accuracy: 0.7440 - val_loss: 0.6344 - learning_rate: 8.0136e-05\n",
      "Epoch 162/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7594 - loss: 0.6065 - val_accuracy: 0.7440 - val_loss: 0.6343 - learning_rate: 8.0136e-05\n",
      "Epoch 163/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7594 - loss: 0.6065 - val_accuracy: 0.7440 - val_loss: 0.6343 - learning_rate: 8.0136e-05\n",
      "Epoch 164/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7590 - loss: 0.6065 - val_accuracy: 0.7440 - val_loss: 0.6343 - learning_rate: 8.0136e-05\n",
      "Epoch 165/2000\n",
      "\u001b[1m92/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.5914\n",
      "Epoch 165: ReduceLROnPlateau reducing learning rate to 4.006809103884734e-05.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.6064 - val_accuracy: 0.7440 - val_loss: 0.6343 - learning_rate: 8.0136e-05\n",
      "Epoch 166/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6046 - val_accuracy: 0.7455 - val_loss: 0.6326 - learning_rate: 4.0068e-05\n",
      "Epoch 167/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6042 - val_accuracy: 0.7455 - val_loss: 0.6328 - learning_rate: 4.0068e-05\n",
      "Epoch 168/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7597 - loss: 0.6042 - val_accuracy: 0.7455 - val_loss: 0.6327 - learning_rate: 4.0068e-05\n",
      "Epoch 169/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7597 - loss: 0.6042 - val_accuracy: 0.7455 - val_loss: 0.6326 - learning_rate: 4.0068e-05\n",
      "Epoch 170/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6041 - val_accuracy: 0.7455 - val_loss: 0.6327 - learning_rate: 4.0068e-05\n",
      "Epoch 171/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6041 - val_accuracy: 0.7455 - val_loss: 0.6326 - learning_rate: 4.0068e-05\n",
      "Epoch 172/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6041 - val_accuracy: 0.7455 - val_loss: 0.6326 - learning_rate: 4.0068e-05\n",
      "Epoch 173/2000\n",
      "\u001b[1m87/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7713 - loss: 0.5890\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 2.003404551942367e-05.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6041 - val_accuracy: 0.7455 - val_loss: 0.6325 - learning_rate: 4.0068e-05\n",
      "Epoch 174/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6031 - val_accuracy: 0.7470 - val_loss: 0.6318 - learning_rate: 2.0034e-05\n",
      "Epoch 175/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6030 - val_accuracy: 0.7470 - val_loss: 0.6319 - learning_rate: 2.0034e-05\n",
      "Epoch 176/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6030 - val_accuracy: 0.7470 - val_loss: 0.6319 - learning_rate: 2.0034e-05\n",
      "Epoch 177/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6030 - val_accuracy: 0.7470 - val_loss: 0.6319 - learning_rate: 2.0034e-05\n",
      "Epoch 178/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6029 - val_accuracy: 0.7470 - val_loss: 0.6319 - learning_rate: 2.0034e-05\n",
      "Epoch 179/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6029 - val_accuracy: 0.7470 - val_loss: 0.6319 - learning_rate: 2.0034e-05\n",
      "Epoch 180/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6029 - val_accuracy: 0.7470 - val_loss: 0.6319 - learning_rate: 2.0034e-05\n",
      "Epoch 181/2000\n",
      "\u001b[1m89/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.5880\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 1.0017022759711836e-05.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6029 - val_accuracy: 0.7470 - val_loss: 0.6319 - learning_rate: 2.0034e-05\n",
      "Epoch 182/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6024 - val_accuracy: 0.7470 - val_loss: 0.6315 - learning_rate: 1.0017e-05\n",
      "Epoch 183/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6024 - val_accuracy: 0.7470 - val_loss: 0.6315 - learning_rate: 1.0017e-05\n",
      "Epoch 184/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6024 - val_accuracy: 0.7470 - val_loss: 0.6315 - learning_rate: 1.0017e-05\n",
      "Epoch 185/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6023 - val_accuracy: 0.7470 - val_loss: 0.6315 - learning_rate: 1.0017e-05\n",
      "Epoch 186/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6023 - val_accuracy: 0.7470 - val_loss: 0.6315 - learning_rate: 1.0017e-05\n",
      "Epoch 187/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6023 - val_accuracy: 0.7470 - val_loss: 0.6315 - learning_rate: 1.0017e-05\n",
      "Epoch 188/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6023 - val_accuracy: 0.7470 - val_loss: 0.6315 - learning_rate: 1.0017e-05\n",
      "Epoch 189/2000\n",
      "\u001b[1m85/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7719 - loss: 0.5874\n",
      "Epoch 189: ReduceLROnPlateau reducing learning rate to 5.008511379855918e-06.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6023 - val_accuracy: 0.7470 - val_loss: 0.6315 - learning_rate: 1.0017e-05\n",
      "Epoch 190/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6021 - val_accuracy: 0.7470 - val_loss: 0.6313 - learning_rate: 5.0085e-06\n",
      "Epoch 191/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6021 - val_accuracy: 0.7470 - val_loss: 0.6313 - learning_rate: 5.0085e-06\n",
      "Epoch 192/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6021 - val_accuracy: 0.7470 - val_loss: 0.6313 - learning_rate: 5.0085e-06\n",
      "Epoch 193/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6021 - val_accuracy: 0.7470 - val_loss: 0.6313 - learning_rate: 5.0085e-06\n",
      "Epoch 194/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6021 - val_accuracy: 0.7470 - val_loss: 0.6313 - learning_rate: 5.0085e-06\n",
      "Epoch 195/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6021 - val_accuracy: 0.7470 - val_loss: 0.6313 - learning_rate: 5.0085e-06\n",
      "Epoch 196/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6020 - val_accuracy: 0.7470 - val_loss: 0.6313 - learning_rate: 5.0085e-06\n",
      "Epoch 197/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.5881\n",
      "Epoch 197: ReduceLROnPlateau reducing learning rate to 2.504255689927959e-06.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6020 - val_accuracy: 0.7470 - val_loss: 0.6313 - learning_rate: 5.0085e-06\n",
      "Epoch 198/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6019 - val_accuracy: 0.7470 - val_loss: 0.6312 - learning_rate: 2.5043e-06\n",
      "Epoch 199/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6019 - val_accuracy: 0.7470 - val_loss: 0.6312 - learning_rate: 2.5043e-06\n",
      "Epoch 200/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6019 - val_accuracy: 0.7470 - val_loss: 0.6312 - learning_rate: 2.5043e-06\n",
      "Epoch 201/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6019 - val_accuracy: 0.7470 - val_loss: 0.6312 - learning_rate: 2.5043e-06\n",
      "Epoch 202/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6019 - val_accuracy: 0.7470 - val_loss: 0.6312 - learning_rate: 2.5043e-06\n",
      "Epoch 203/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6019 - val_accuracy: 0.7470 - val_loss: 0.6312 - learning_rate: 2.5043e-06\n",
      "Epoch 204/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6019 - val_accuracy: 0.7470 - val_loss: 0.6312 - learning_rate: 2.5043e-06\n",
      "Epoch 205/2000\n",
      "\u001b[1m82/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7720 - loss: 0.5871\n",
      "Epoch 205: ReduceLROnPlateau reducing learning rate to 1.2521278449639794e-06.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6019 - val_accuracy: 0.7470 - val_loss: 0.6312 - learning_rate: 2.5043e-06\n",
      "Epoch 206/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.2521e-06\n",
      "Epoch 207/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.2521e-06\n",
      "Epoch 208/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.2521e-06\n",
      "Epoch 209/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.2521e-06\n",
      "Epoch 210/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.2521e-06\n",
      "Epoch 211/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.2521e-06\n",
      "Epoch 212/2000\n",
      "\u001b[1m90/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7718 - loss: 0.5870\n",
      "Epoch 212: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.2521e-06\n",
      "Epoch 213/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 214/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 215/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 216/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 217/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 218/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 219/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 220/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 221/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 222/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 223/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 224/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 225/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 226/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 227/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 228/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 229/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 230/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 231/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 232/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 233/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 234/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 235/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 236/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 237/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 238/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 239/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 240/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 241/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 242/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 243/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 244/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 245/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 246/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 247/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 248/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 249/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 250/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 251/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 252/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 253/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 254/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 255/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 256/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 257/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 258/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 259/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 260/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 261/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 262/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 263/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 264/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 265/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 266/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 267/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 268/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 269/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 270/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 271/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 272/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 273/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 274/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 275/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 276/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 277/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 278/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 279/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 280/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 281/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 282/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 283/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 284/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 285/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 286/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 287/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 288/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 289/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 290/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 291/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 292/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 293/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 294/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 295/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 296/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 297/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 298/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 299/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 300/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 301/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 302/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 303/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 304/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 305/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 306/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 307/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 308/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 309/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 310/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 311/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 312/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 313/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 314/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 315/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 316/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 317/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 318/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 319/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 320/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 321/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 322/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 323/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 324/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 325/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 326/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 327/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 328/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 329/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 330/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 331/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 332/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 333/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 334/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 335/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 336/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6311 - learning_rate: 1.0000e-06\n",
      "Epoch 337/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 338/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 339/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 340/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 341/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 342/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 343/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 344/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 345/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 346/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 347/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 348/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 349/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 350/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 351/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 352/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 353/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 354/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 355/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 356/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 357/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 358/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 359/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 360/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 361/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 362/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 363/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 364/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6018 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 365/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 366/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 367/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 368/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 369/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 370/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 371/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 372/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 373/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 374/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 375/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 376/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 377/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 378/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 379/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 380/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 381/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 382/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 383/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 384/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 385/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 386/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 387/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 388/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 389/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 390/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 391/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 392/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 393/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 394/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 395/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 396/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 397/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 398/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 399/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 400/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 401/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 402/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 403/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 404/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 405/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 406/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 407/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 408/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 409/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 410/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 411/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 412/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 413/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 414/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 415/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 416/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 417/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 418/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 419/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 420/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 421/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 422/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 423/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 424/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 425/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 426/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 427/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 428/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 429/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 430/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 431/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 432/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 433/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 434/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 435/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 436/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 437/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 438/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 439/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 440/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 441/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 442/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 443/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 444/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 445/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 446/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 447/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 448/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 449/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 450/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 451/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 452/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 453/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 454/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 455/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 456/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 457/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 458/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 459/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 460/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 461/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 462/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 463/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 464/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 465/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 466/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 467/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 468/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 469/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 470/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 471/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 472/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 473/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 474/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 475/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 476/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 477/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 478/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 479/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 480/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 481/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 482/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 483/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 484/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 485/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 486/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 487/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 488/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 489/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 490/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 491/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 492/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 493/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 494/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 495/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 496/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 497/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 498/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 499/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 500/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 501/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 502/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 503/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 504/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 505/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 506/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 507/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 508/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 509/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 510/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 511/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 512/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 513/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 514/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 515/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 516/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 517/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 518/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 519/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 520/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 521/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 522/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 523/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 524/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 525/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 526/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 527/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7607 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 528/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 529/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 530/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 531/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 532/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 533/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 534/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 535/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 536/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 537/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 538/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 539/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 540/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 541/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 542/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 543/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 544/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 545/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 546/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 547/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 548/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 549/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 550/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 551/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 552/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 553/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 554/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 555/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 556/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 557/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 558/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 559/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 560/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6310 - learning_rate: 1.0000e-06\n",
      "Epoch 561/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 562/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 563/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 564/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 565/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 566/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 567/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 568/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 569/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 570/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 571/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 572/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 573/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 574/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 575/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 576/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 577/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 578/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 579/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 580/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 581/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 582/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 583/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 584/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 585/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 586/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 587/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 588/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 589/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 590/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 591/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 592/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 593/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 594/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 595/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 596/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 597/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 598/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 599/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 600/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 601/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 602/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 603/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 604/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 605/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 606/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 607/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 608/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 609/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 610/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 611/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 612/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 613/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 614/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 615/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 616/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 617/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 618/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 619/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 620/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 621/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 622/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 623/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 624/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 625/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 626/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 627/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 628/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 629/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 630/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 631/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 632/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 633/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 634/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 635/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 636/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 637/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 638/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 639/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 640/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6017 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 641/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 642/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 643/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 644/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 645/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 646/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 647/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 648/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 649/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 650/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 651/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 652/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 653/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 654/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 655/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 656/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 657/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 658/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 659/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 660/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 661/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 662/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 663/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 664/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 665/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 666/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 667/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 668/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 669/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 670/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 671/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 672/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 673/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 674/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 675/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 676/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 677/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 678/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 679/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 680/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 681/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 682/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 683/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 684/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 685/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 686/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 687/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 688/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 689/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 690/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 691/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 692/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 693/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 694/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 695/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 696/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 697/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 698/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 699/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 700/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 701/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 702/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 703/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 704/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 705/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 706/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 707/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 708/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 709/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 710/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 711/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 712/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 713/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 714/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 715/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6309 - learning_rate: 1.0000e-06\n",
      "Epoch 716/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 717/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 718/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 719/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 720/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 721/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 722/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 723/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 724/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 725/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 726/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 727/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 728/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 729/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 730/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 731/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 732/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 733/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 734/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 735/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 736/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 737/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 738/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 739/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 740/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 741/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 742/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 743/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 744/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 745/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 746/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 747/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 748/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 749/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 750/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 751/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 752/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 753/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 754/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 755/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 756/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 757/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 758/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 759/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 760/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 761/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 762/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 763/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 764/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 765/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 766/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 767/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 768/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 769/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 770/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 771/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 772/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 773/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 774/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 775/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 776/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 777/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 778/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 779/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 780/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 781/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 782/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 783/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 784/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 785/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 786/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 787/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 788/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 789/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 790/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 791/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 792/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 793/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 794/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 795/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 796/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 797/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 798/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 799/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 800/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 801/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 802/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 803/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 804/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 805/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 806/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 807/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 808/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 809/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 810/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 811/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 812/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 813/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 814/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 815/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 816/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 817/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 818/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 819/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 820/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 821/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 822/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 823/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 824/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 825/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 826/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 827/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 828/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 829/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 830/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 831/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 832/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 833/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 834/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 835/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 836/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 837/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 838/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 839/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 840/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 841/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 842/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 843/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 844/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 845/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 846/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 847/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 848/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6308 - learning_rate: 1.0000e-06\n",
      "Epoch 849/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 850/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 851/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 852/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 853/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 854/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 855/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 856/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 857/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 858/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 859/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 860/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 861/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 862/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 863/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 864/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 865/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 866/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 867/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 868/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 869/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 870/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 871/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 872/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 873/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 874/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 875/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 876/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 877/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 878/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 879/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 880/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 881/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 882/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 883/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 884/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 885/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 886/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 887/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 888/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 889/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 890/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 891/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 892/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 893/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 894/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 895/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 896/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 897/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 898/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 899/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 900/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 901/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 902/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 903/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 904/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 905/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 906/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 907/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 908/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 909/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 910/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 911/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 912/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 913/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 914/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 915/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 916/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 917/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 918/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 919/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 920/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 921/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 922/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 923/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 924/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 925/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 926/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6016 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 927/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 928/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 929/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 930/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 931/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 932/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 933/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 934/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 935/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 936/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 937/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 938/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 939/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 940/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 941/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 942/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 943/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 944/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 945/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 946/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 947/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 948/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 949/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 950/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 951/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 952/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 953/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 954/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 955/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 956/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 957/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 958/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 959/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 960/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 961/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 962/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 963/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 964/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 965/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 966/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 967/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 968/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 969/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 970/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 971/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6307 - learning_rate: 1.0000e-06\n",
      "Epoch 972/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 973/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 974/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 975/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 976/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 977/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 978/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 979/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 980/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 981/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 982/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 983/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 984/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 985/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 986/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 987/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 988/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 989/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 990/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 991/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 992/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 993/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 994/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 995/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 996/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 997/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 998/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 999/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1000/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1001/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1002/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1003/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1004/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1005/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1006/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1007/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1008/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1009/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1010/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1011/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1012/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1013/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1014/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1015/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1016/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1017/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1018/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1019/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1020/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1021/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1022/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1023/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1024/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1025/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1026/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1027/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1028/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1029/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1030/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1031/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1032/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1033/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1034/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1035/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1036/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1037/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1038/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1039/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1040/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1041/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1042/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1043/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1044/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1045/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1046/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1047/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1048/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1049/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1050/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1051/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1052/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1053/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1054/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1055/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1056/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1057/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1058/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1059/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1060/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1061/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1062/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1063/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1064/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1065/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1066/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1067/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1068/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1069/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1070/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1071/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1072/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1073/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1074/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1075/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1076/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1077/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1078/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1079/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1080/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1081/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1082/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1083/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1084/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1085/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1086/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1087/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1088/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1089/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1090/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1091/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1092/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1093/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1094/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1095/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1096/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1097/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1098/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1099/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1100/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1101/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1102/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1103/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1104/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1105/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1106/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1107/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6306 - learning_rate: 1.0000e-06\n",
      "Epoch 1108/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1109/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1110/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1111/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1112/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1113/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1114/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1115/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1116/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1117/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1118/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1119/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1120/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1121/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1122/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1123/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1124/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1125/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1126/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1127/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1128/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1129/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1130/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1131/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1132/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1133/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1134/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1135/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1136/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1137/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1138/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1139/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1140/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1141/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1142/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1143/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1144/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1145/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1146/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1147/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1148/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1149/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1150/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1151/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1152/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1153/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1154/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1155/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1156/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1157/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1158/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1159/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1160/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1161/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1162/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1163/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1164/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1165/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1166/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1167/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1168/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1169/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1170/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1171/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1172/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1173/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1174/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1175/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1176/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1177/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1178/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1179/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1180/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1181/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1182/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1183/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1184/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1185/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1186/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1187/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1188/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1189/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1190/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1191/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1192/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1193/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1194/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1195/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1196/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1197/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1198/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1199/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1200/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1201/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1202/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1203/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1204/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1205/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1206/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1207/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1208/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1209/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1210/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1211/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1212/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1213/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1214/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1215/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1216/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6015 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1217/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1218/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1219/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1220/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1221/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1222/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1223/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1224/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1225/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1226/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1227/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1228/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1229/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1230/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1231/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1232/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1233/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1234/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1235/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1236/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1237/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1238/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1239/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1240/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1241/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1242/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1243/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1244/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1245/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1246/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1247/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1248/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1249/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1250/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1251/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1252/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1253/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1254/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1255/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1256/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1257/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1258/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1259/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1260/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6305 - learning_rate: 1.0000e-06\n",
      "Epoch 1261/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1262/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1263/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1264/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1265/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1266/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1267/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1268/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1269/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1270/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1271/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1272/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1273/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1274/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1275/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1276/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1277/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1278/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1279/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1280/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1281/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1282/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1283/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1284/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1285/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1286/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1287/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1288/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1289/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1290/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1291/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1292/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1293/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1294/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1295/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1296/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1297/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1298/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1299/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1300/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1301/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1302/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1303/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1304/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1305/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1306/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1307/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1308/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1309/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1310/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1311/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1312/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1313/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1314/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1315/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1316/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1317/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1318/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1319/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1320/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1321/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1322/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1323/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1324/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1325/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1326/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1327/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1328/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1329/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1330/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1331/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1332/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1333/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1334/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1335/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1336/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1337/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1338/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1339/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1340/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1341/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1342/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1343/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1344/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1345/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1346/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1347/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1348/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1349/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6304 - learning_rate: 1.0000e-06\n",
      "Epoch 1350/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1351/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1352/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1353/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1354/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1355/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1356/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1357/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1358/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1359/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1360/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1361/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1362/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1363/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1364/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1365/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1366/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1367/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1368/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1369/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1370/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1371/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1372/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1373/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1374/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1375/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1376/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1377/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1378/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1379/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1380/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1381/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1382/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1383/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1384/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1385/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1386/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1387/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1388/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1389/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1390/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1391/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1392/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1393/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1394/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1395/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1396/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1397/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1398/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1399/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1400/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1401/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1402/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1403/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1404/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1405/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1406/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1407/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1408/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1409/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1410/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1411/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1412/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1413/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1414/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1415/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1416/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1417/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1418/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1419/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1420/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1421/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1422/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1423/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1424/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1425/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1426/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1427/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1428/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1429/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1430/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1431/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1432/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1433/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1434/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1435/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1436/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1437/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1438/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1439/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1440/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1441/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1442/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1443/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1444/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1445/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1446/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1447/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1448/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1449/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1450/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1451/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1452/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1453/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1454/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1455/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1456/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1457/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1458/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1459/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1460/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1461/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1462/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1463/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1464/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1465/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1466/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1467/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1468/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1469/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1470/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1471/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1472/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1473/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1474/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1475/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1476/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1477/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1478/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1479/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1480/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1481/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1482/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1483/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1484/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1485/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1486/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1487/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1488/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1489/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1490/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1491/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1492/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1493/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1494/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1495/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1496/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1497/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1498/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1499/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1500/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1501/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1502/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1503/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1504/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1505/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1506/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1507/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1508/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1509/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1510/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6014 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1511/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1512/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1513/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1514/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6303 - learning_rate: 1.0000e-06\n",
      "Epoch 1515/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1516/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1517/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1518/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1519/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1520/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1521/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1522/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1523/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1524/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1525/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1526/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1527/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1528/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1529/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1530/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1531/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1532/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1533/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1534/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1535/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1536/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1537/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1538/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1539/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1540/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1541/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1542/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1543/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1544/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1545/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1546/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1547/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1548/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1549/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1550/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1551/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1552/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1553/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1554/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1555/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1556/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1557/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1558/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1559/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1560/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1561/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1562/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1563/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1564/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1565/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1566/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1567/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1568/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1569/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1570/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1571/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1572/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1573/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1574/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1575/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1576/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1577/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1578/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1579/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1580/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1581/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1582/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1583/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1584/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1585/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1586/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1587/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1588/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1589/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1590/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1591/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1592/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1593/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1594/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1595/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1596/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1597/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1598/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1599/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1600/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1601/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1602/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1603/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1604/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1605/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1606/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1607/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1608/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1609/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1610/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1611/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1612/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1613/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1614/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1615/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1616/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1617/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1618/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1619/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1620/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1621/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1622/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1623/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1624/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1625/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1626/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1627/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1628/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1629/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1630/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1631/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1632/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1633/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1634/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1635/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1636/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1637/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1638/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1639/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1640/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1641/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1642/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1643/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1644/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1645/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1646/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1647/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1648/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1649/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1650/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1651/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1652/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1653/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1654/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1655/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1656/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1657/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1658/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1659/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1660/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1661/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1662/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1663/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1664/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1665/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1666/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1667/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1668/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1669/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1670/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1671/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1672/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1673/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1674/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1675/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1676/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1677/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1678/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1679/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1680/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1681/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1682/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1683/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1684/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1685/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1686/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1687/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1688/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1689/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1690/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1691/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1692/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1693/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6302 - learning_rate: 1.0000e-06\n",
      "Epoch 1694/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1695/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1696/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1697/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1698/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1699/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1700/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1701/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1702/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1703/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1704/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1705/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1706/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1707/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1708/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1709/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1710/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1711/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1712/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1713/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1714/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1715/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1716/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1717/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1718/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1719/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1720/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1721/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1722/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1723/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1724/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1725/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1726/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1727/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1728/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1729/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1730/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1731/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1732/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1733/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1734/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1735/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1736/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1737/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1738/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1739/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1740/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1741/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1742/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1743/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1744/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1745/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1746/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1747/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1748/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1749/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1750/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1751/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1752/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1753/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1754/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1755/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1756/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1757/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1758/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1759/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1760/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1761/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1762/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1763/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1764/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1765/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1766/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1767/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1768/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1769/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1770/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1771/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1772/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1773/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1774/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1775/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1776/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1777/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1778/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1779/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1780/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1781/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1782/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1783/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1784/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1785/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1786/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1787/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1788/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1789/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1790/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1791/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1792/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1793/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1794/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1795/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1796/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6013 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1797/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1798/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1799/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1800/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1801/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1802/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1803/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1804/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1805/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1806/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1807/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1808/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1809/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1810/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1811/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1812/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1813/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1814/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1815/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1816/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1817/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1818/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1819/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1820/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1821/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1822/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1823/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n",
      "Epoch 1824/2000\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.6012 - val_accuracy: 0.7470 - val_loss: 0.6301 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d6edeb9010>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=2000, validation_data=(X_val, y_val), callbacks=callbacks_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c5f79",
   "metadata": {},
   "source": [
    "### Training Performance\n",
    "\n",
    "Both training and validation loss decreased rapidly during the first epochs and then leveled off around 0.6, indicating stable convergence and no significant overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6a0a860f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441f084c",
   "metadata": {},
   "source": [
    "### Model Accuracy\n",
    "\n",
    "Training and validation accuracy increased quickly during the initial epochs.\n",
    "Afterward, training accuracy continued to rise slightly, while validation accuracy stabilized around 0.75, indicating good model convergence without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0cb08110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df[['accuracy', 'val_accuracy']].plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe6fb0",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "The model achieved an accuracy of 0.76 on the training data and 0.76 on the test data, with loss values around 0.58–0.64.\n",
    "The similar results across both datasets indicate good generalization and no signs of overfitting.\n",
    "This evaluation was performed using code adapted from the exercise notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2b8d5151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data evaluation:\n",
      "[0.6395938396453857, 0.759036123752594]\n",
      "\n",
      "Train data evaluation:\n",
      "[0.5764860510826111, 0.7732558250427246]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dc54b971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2a1950d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"Dropout\", \"Enrolled\", \"Graduate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b771df",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "The confusion matrix shows that the model correctly classified most samples for the Graduate and Dropout classes.\n",
    "Some confusion remains between Dropout and Enrolled, with the Enrolled class showing the highest misclassification rate.\n",
    "Overall, the model demonstrates strong predictive performance, particularly for the Graduate category.\n",
    "This visualization was created using code adapted from the exercise notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "03b69630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGdCAYAAACGtNCDAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQwtJREFUeJzt3Qd4FFXXwPEzoQQIJBB66D10EKSLdAQEKRZ8qdIU6SBgFEIRAUGaSBGVpmABQelIxwLSe1GKgvRek5CE/Z57+bLsbECSsMluMv8fzzy7OzM73GQnu2fPPfeOYbPZbAIAAPD/vKLuAAAAKAQHAADAhOAAAACYEBwAAAATggMAAGBCcAAAAEwIDgAAgAnBAQAAMCE4AAAAJsnFQ7y34k93NwEeZEDNAu5uAjzIrZAIdzcBHiaXv3e8Hj912e4uO1bI7k8lsfGY4AAAAI9hWDuxbu2fHgAAREPmAAAAZ4YhVkZwAACAM8PaiXWCAwAAnBnWzhxYOzQCAADRkDkAAMCZYe3vzgQHAAA4M+hWAAAAsCNzAACAM8Pa350JDgAAcGbQrQAAAGBH5gAAAGeGtb87ExwAAODMoFsBAADAjswBAADODGt/dyY4AADAmWHtbgWCAwAAnBnWzhxY+6cHAMCDTJs2TUqVKiW+vr56qVy5sqxcudK+PTQ0VLp16yYZM2aUtGnTSosWLeTChQumY5w6dUoaNWokadKkkSxZskj//v0lIiIiVu0gOAAA4FGZA8NFSyzkzJlTRo8eLTt37pQdO3ZIrVq15KWXXpKDBw/q7X369JGlS5fKggULZNOmTXL27Flp3ry5/fmRkZE6MLh37578/vvvMmfOHJk9e7YEBwfH7se32Ww28QDvrfjT3U2ABxlQs4C7mwAPciskdt96kPTl8veO1+OnrvmBy44VsmHwUz3f399fxo4dKy+//LJkzpxZ5s+fr+8rR44ckaJFi8qWLVukUqVKOsvw4osv6qAha9asep/p06fLwIED5dKlS5IyZcoY/Z9kDgAAiEdhYWFy8+ZN06LWPYnKAnz77bdy584d3b2gsgnh4eFSp04d+z6BgYGSO3duHRwo6rZkyZL2wECpX7++/j+jsg8xQXAAAEA8diuMGjVK/Pz8TIta9zj79+/X9QTe3t7y1ltvyeLFi6VYsWJy/vx5/c0/ffr0pv1VIKC2KerWMTCI2h61LaYYrQAAQDwOZQwKCpK+ffua1qkP/scpUqSI7NmzR27cuCELFy6Udu3a6fqChERwAABAPPL29v7PYMCZyg4ULFhQ3y9Xrpxs375dJk2aJK+99pouNLx+/bope6BGK2TLlk3fV7fbtm0zHS9qNEPUPjFBtwIAAB4yWuFR7t+/r2sUVKCQIkUKWbdunX3b0aNH9dBFVZOgqFvVLXHx4kX7PmvWrNHDIlXXREyROQAAwENmSAwKCpIGDRroIsNbt27pkQkbN26U1atX61qFjh076i4KNYJBfeD36NFDBwRqpIJSr149HQS0adNGxowZo+sMBg0apOdGiE32guAAAAAPcfHiRWnbtq2cO3dOBwNqQiQVGNStW1dvnzBhgnh5eenJj1Q2QY1EmDp1qv35yZIlk2XLlknXrl110ODj46NrFoYPHx6rdjDPATwS8xzAEfMcIMHnOag31mXHCvm5vyQ2ZA4AAHBmcOElAADgyLB2vb61f3oAABANmQMAAJwZdCsAAABHhrUT69b+6QEAQDRkDgAAcGZYu1shTpkDNcmC49SMUa5cuaK3AQCQqBmeM32yO8Sp1Y+bN0nN1qQuGAEAACzSrfDJJ5/oW8Mw5IsvvtDXm44SGRkpmzdvlsDAQNe3EgCAhGQkzm/8bgkO1JzOUZmD6dOnm7oQVMYgb968ej0AAImaYe2ag1gFBydPntS3NWvWlEWLFkmGDBniq10AACAxjVbYsGGD61sCAICnMOhWiLUOHTr85/aZM2fGtT0AALifQbdCrF27ds30ODw8XA4cOCDXr1+XWrVquaptAAC4h0HmINYWL14cbd39+/ela9euUqBAAVe0CwAAuInLQiMvLy/p27evfUQDAACJulvBcNFi9emTjx8/LhEREa48JAAACc5IpB/qbg0OVIbAkZr34Ny5c7J8+XJp166dq9oGAAASS3Cwe/fuaF0KmTNnlnHjxj1xJAMAAJ7OIHMQe8xzAABI0gyxtKeqObh06ZIcPXpU3y9SpIjOHgAAAAuOVrhz547uPsiePbtUr15dLwEBAdKxY0e5e/eu61sJAEACdysYLloSI6+4FiRu2rRJli5dqic+UstPP/2k1/Xr18/1rQQAIAEZFg8O4tSt8MMPP8jChQulRo0a9nUNGzaU1KlTy6uvvirTpk1zZRsBAICnBweq6yBr1qzR1mfJkoVuBQBAomck0m/8bg0OKleuLEOGDJG5c+dKqlSp9LqQkBAZNmyY3oaHLh0/IH+uXyTX/z0uoTevSqUO70mOkg9/RzvmT5B/tq83PSdr4DNS7c1h9sdH1nwn5w7tkBtnTohXshTSZNS3CfozIH7t3rlDvp4zU44cPiiXL12SMeM/kedr1bFvr1im2COf1713P2nTvmMCthQJYcmi72Tpou/lwrmz+nGe/AWkTYc3pULl5/Tjq1cuy4xPx8vObVsk5O4dyZk7r/yvfWepXrOum1uetBgEB7E3adIkqV+/vuTMmVNKly6t1+3du1cHCqtXr3Z1GxO1yHuhkj5HPslbsa5snTXykfuoYKD8673tj72SpzBtvx8RITlLV5WMeQPl761r4r3NSFghIXelUOEi0rhpcxnYt2e07SvWbjI9/v3XX+TDYYOlVp16CdhKJJTMmbNKp7d7S45cudUMc/LziiUSPKCXTJ/zveTNX1A+Gv6+3L51Sz4Y84n4ps8g639eISMG9ZcpM7+RQkWKurv5SYchlhan4KBEiRLy119/ybx58+TIkSN63euvvy6tWrXSdQd4KFvR8nr5LyoYSOWb4bHbizVopW//3rbW5e2D+1WpVl0vj5Mxk3mI8OaN66XcsxUkR85cCdA6JLTKzz2s5VI6vNVTZxIOH9ing4OD+/dIr/6DJLB4Sb299Rtd5Idvv5K/jh4iOID75zlIkyaNdO7c2XUtsbDLxw7IssGtJUXqtJK5UCkp3rC1ePv4urtZ8EBXrlyW337dLEOGPzoLhaQlMjJSNq//WUJDQ6RYyQdZ2uIly8jGtaulYpXqkjZdOtm0brWE3wuT0mWfdXdzkxSDboW4UZMfTZ48WQ4fPqwfFy1aVLp37y6BgYFPfG5YWJheHEWE35PkKVKK1WQNLCcBpaqIj39WuX3lnBxc/pX8NmOo1Ow1VgyvZO5uHjzMiiU/iU+aNFKjNv3LSdmJY39Kzy5t5N69e5I6dRoZOnqi5MlXQG8bPGKsfDB4gDR/4TlJliy5eKdKpbfrbgi4jGHx4MArrkMZVdfCzp07dc2BWnbt2iUlS5bU255k1KhR4ufnZ1q2fP+ZWFGuZ6pLQImK4heQVxcqVukULNdO/SWXjh1wd9PggZb+tEjqN3xRvL293d0UxKNcefLJZ3MWyKdfzJPGzV6VMR8Mkn9OHtfbZs2YIndu3ZQxn8yQqbO+kZdfbyMfDOqvAwrArZmDAQMGSFBQkAwfPty0Xo1gUNtatGjxn89Xz3W+suOIDafi0pQkJ22mbJLSx1duXz4rWQo/SCMCyu5dO+Sfv0/KiI/GubspiGcpUqSwZwIKBxaTo4cPyKLv5slrrd+QnxZ+I1/MW6TrD5QChYrI/j27ZMkP30nvgYPd3PKkwyBzEHvq8sxt27aNtr5169Z625Oobz2+vr6mxYpdCo9y9/pluXf3lqTy9Xd3U+Bhli5eJIHFikvhIk/uukPSYrPdl/Dwe7r2QDG8zG/dXsmSyX3bfTe1LmkyLD5DYpyCAzUz4i+//BJt/a+//irPPfdgLC4eiAgLketnTuhFuXvlgr5/99pFvW3fkply5e8jcufqBbn4517Z8uUISZspux7eGEXtq54Tcu2SfpOIOp56PhK/u3fvyJ9HDutFOXvmjL5//v/HuSu3b9+WdWtWy0vN/jsrh8Tvi6mTZN/uHXL+3BndVaAe7921Q2rXbyS58+aTHDlzy8SPhsuRg/vl7L+nZcH8ObJr2xapWr2Wu5sOq3crNGnSRAYOHKhrDipVqqTXbd26VRYsWKAnQlqyZIlpXyu7dvqYbJ7ynv3xvp++1Ld5nq0lZV9+W26c/VtObV8v90LuSGpff8lSpKwUb9hKkjnMdXBo5TzTREnrPu6lb6t3GymZCz4YzoTE6/DBg/J25/b2xxPHfaRvGzVuKsEfPBiVsGbVCrGJTeq90Mht7UTCuH7tqnw0fJBcvXJJfNKmlXwFCsvoidOlXIUHk6d9OH6KfDF1ogzq30NCQ+5KQM7cMmDwCKlYhS9mLmWIpRk2m80W2yd5OaW0Hntww9BDcWLivRUU0+ChATUfVGYDyq2QCHc3AR4ml3/8FuVmau+6mWgvz24plsgc3L9P3xYAAElVnOc5AAAgqTISaSGhWwsSlU2bNknjxo2lYMGCelG1BY8qUgQAILExGK0Qe19//bXUqVNHT6Hcs2dPvahrKtSuXVvmz5/v+lYCAJCQDBcuVulW+PDDD2XMmDHSp08f+zoVIIwfP14++OAD+d///ufKNgIAAE/PHJw4cUJ3KThTXQsnT550RbsAAHAbg26F2MuVK5esW7cu2vq1a9fqbQAAJGaGxYODOHUr9OvXT3cj7NmzR6pUqaLX/fbbbzJ79myZNGmSq9sIAAA8PTjo2rWrZMuWTcaNGyfff/+9/ZLN3333nbz00kuubiMAAAnKSKTf+N0WHERERMjIkSOlQ4cO+loKAAAkNYbFg4NY1xwkT55cj1RQQQIAAHCdUaNGybPPPivp0qWTLFmySNOmTeXo0aPRLn7oXNfw1ltvmfY5deqUNGrUSE85oI7Tv3//WH1ux6kgUc1noCZBAgAgSTLcM8+B+mzt1q2bvpjhmjVrJDw8XOrVqyd37twx7de5c2c5d+6cfVFf2qOoaxqpwODevXvy+++/y5w5c3RNYHBwcPzWHDRo0EDeffdd2b9/v5QrV058fHxM261+JUYAQOJmuKlbYdWqVabH6kNdffNXV0GuXr26fb3KCKjav0f5+eef5dChQ3oEYdasWaVMmTJ6DiJ1NeWhQ4dKypQp4yc4ePvtt/WtmvToaa7ECAAAHu/GjRv61t/f37R+3rx5erZiFSCoeYcGDx6sAwZly5YtUrJkSR0YRKlfv74eTHDw4EEpW7asPAlXZQQAIB4zB2FhYXpx5O3trZcnfdb27t1bqlatKiVKlLCvV7MQ58mTRwICAmTfvn06I6DqEhYtWqS3nz9/3hQYKFGP1baYiHVwoBqr0hyqEX///bf+BebPn19atGghbdq0sXyFJwAg8TNc+FmmigyHDRtmWjdkyBCd4v8vqvbgwIED0UYGdunSxX5fZQiyZ8+uawGPHz8uBQoUcEmbY1WQaLPZdD1Bp06d5MyZM7pRxYsX10FC+/btpVmzZi5pFAAASaUgMSgoSHcPOC5q3X/p3r27LFu2TDZs2CA5c+b8z30rVqyob48dO6ZvVVfDhQsXTPtEPX5cncJTZQ5UxmDz5s166uSaNWuatq1fv14PuZg7d660bds2NocFACDJ8o5BF4Ljl/AePXrI4sWLZePGjZIvX74nPkfNVqyoDIJSuXJlfYHEixcv6mJGRY188PX1lWLFirk+c/DNN9/Ie++9Fy0wUGrVqqVHMKgiCQAAEjPDTddWUF0JqtBw/vz5eq4DVSOglpCQEL1ddR2okQdq9ILK2i9ZskR/IVcjGUqVKqX3UUMfVRCguvr37t0rq1evlkGDBuljxzRIiVVwoAofXnjhhf8c4qgaAgBAYma4KTiYNm2a7nZQEx2pTEDUoi5PoKhhiGqIogoAAgMD9bWOVM3f0qVL7cdIliyZ7pJQtyqL0Lp1ax1ADB8+PMbtiFW3wtWrV6NVQDpS265duxabQwIAAIduhf+irnwck0kI1WiGFStWSFzFKjhQ8xeo6ZMfR0UpTKsMAEjsDIuPvEse24hGjUp4XJ+F8zhOAAASI4PgIObatWv3xH0YqQAAgIWCg1mzZsVfSwAA8BSGWFqcpk8GACApMyzerRCnSzYDAICki8wBAABODItnDggOAABwYlg7NiA4AADAmWHx6ICaAwAAYELmAAAAJ4a1EwcEBwAAODMsHh3QrQAAAEzIHAAA4MSwduKA4AAAAGdeXtaODuhWAAAAJmQOAABwYlg7cUBwAACAM8Pi0QHdCgAAwITMAQAATgxrJw4IDgAAcGZYPDogOAAAwIlh8eCAmgMAAGBC5gAAACeGtRMHBAcAADgzLB4d0K0AAABMyBwAAODEsHbigOAAAABnhsWjA7oVAACACZkDAACcGNZOHBAcAADgzLB4dEC3AgAAMCFzAACAE8PaiQOCAwAAnBkWjw4IDgAAcGJYOzbwnOCgV7V87m4CPMjdsEh3NwEe5A7nA2DN4AAAAE9hWDx1QHAAAIATw9qxAUMZAQCAGZkDAACcGBZPHRAcAADgxLB2bEC3AgAAMCNzAACAE8PiqQOCAwAAnBgWDw7oVgAAACZkDgAAcGJYO3FAcAAAgDPD4tEBwQEAAE4Ma8cG1BwAAOApRo0aJc8++6ykS5dOsmTJIk2bNpWjR4+a9gkNDZVu3bpJxowZJW3atNKiRQu5cOGCaZ9Tp05Jo0aNJE2aNPo4/fv3l4iIiBi3g+AAAIBHdCsYLlpiY9OmTfqDf+vWrbJmzRoJDw+XevXqyZ07d+z79OnTR5YuXSoLFizQ+589e1aaN29u3x4ZGakDg3v37snvv/8uc+bMkdmzZ0twcHDMf36bzWYTD3DhZri7mwAPEnnfI05LeIibITH/xgNrCMyeJl6PX3vyFpcda12PynF+7qVLl/Q3fxUEVK9eXW7cuCGZM2eW+fPny8svv6z3OXLkiBQtWlS2bNkilSpVkpUrV8qLL76og4asWbPqfaZPny4DBw7Ux0uZMuUT/18yBwAAxKOwsDC5efOmaVHrYkIFA4q/v7++3blzp84m1KlTx75PYGCg5M6dWwcHirotWbKkPTBQ6tevr//fgwcPxuj/JTgAAMCJl2G4bFF1BH5+fqZFrXuS+/fvS+/evaVq1apSokQJve78+fP6m3/69OlN+6pAQG2L2scxMIjaHrUtJhitAABAPI5WCAoKkr59+5rWeXt7P/F5qvbgwIED8uuvv0pCIzgAACAeeXt7xygYcNS9e3dZtmyZbN68WXLmzGlfny1bNl1oeP36dVP2QI1WUNui9tm2bZvpeFGjGaL2eRK6FQAA8JDRCjabTQcGixcvlvXr10u+fPlM28uVKycpUqSQdevW2depoY5q6GLlyg8KH9Xt/v375eLFi/Z91MgHX19fKVasWIzaQeYAAAAnXm6aBEl1JaiRCD/99JOe6yCqRkDVKaROnVrfduzYUXdTqCJF9YHfo0cPHRCokQqKGvqogoA2bdrImDFj9DEGDRqkjx3TDAbBAQAAHjJ98rRp0/RtjRo1TOtnzZol7du31/cnTJggXl5eevIjNepBjUSYOnWqfd9kyZLpLomuXbvqoMHHx0fatWsnw4cPj3E7mOcAHol5DuCIeQ6Q0PMcNJxu7rN/GiveqiCJDZkDAACcGBa/tgLBAQAATgyxdnTAaAUAAGBC5gAAAA8ZreApCA4AAPCQ0Qqegm4FAABgQuYAAAAnhrUTBwQHAAA487J4dEC3AgAAMCFzAACAE8PaiQOCAwAAnBkWjw4IDgAAcGJYOzag5gAAAMQxc7BkyZKY7ipNmjSJ8b4AAHgaL4unDmIcHDRt2jRaf4zj1Z4d+2ciIyNd1T4AABKcIdYW426F+/fv25eff/5ZypQpIytXrpTr16/rZcWKFfLMM8/IqlWr4rfFAADA8woSe/fuLdOnT5dq1arZ19WvX1/SpEkjXbp0kcOHD7uyjQAAJCiDboXYO378uKRPnz7aej8/P/n7779d0S4AANzGy9qxQdxGKzz77LPSt29fuXDhgn2dut+/f3+pUKGCK9sHAAASQ+Zg5syZ0qxZM8mdO7fkypVLrzt9+rQUKlRIfvzxR1e3EQCABGXQrRB7BQsWlH379smaNWvkyJEjel3RokWlTp06lv+FAgASP8PiH2VxniFRBQH16tWT6tWri7e3N0EBAABWrjlQwxk/+OADyZEjh6RNm1ZOnjyp1w8ePFi+/PJLV7cRAIAEZRiGyxbLBAcjRoyQ2bNny5gxYyRlypT29SVKlJAvvvjCle0DAMAtoxW8XLRYJjiYO3euzJgxQ1q1aiXJkiWzry9durS9BgEAgMTKIHMQe2fOnNFFiY/qbggPD3dFuwAAQGIKDooVKya//PJLtPULFy6UsmXLuqJdAAC4jeHCxTKjFYKDg6Vdu3Y6g6CyBYsWLZKjR4/q7oZly5a5vpUAACQgr0TaHeDWzMFLL70kS5culbVr14qPj48OFtT1FNS6unXrur6VAADA8+c5eO655/QkSAAAJDWGtRMHcQ8OAABIqgyLRwcxDg4yZMgQ41/W1atXn6ZNAAAgMQQHEydOjN+WWMTXsz6XzRvWyj//nBRv71RSolQZeat7H8mdN599nyuXL8u0Tz6WHX9skbt370quPHmlTYcuUqMW9RxJzU8/fCdLFn0n58+e1Y/z5i8gbTu+JRWrPKcfjxs1THZt3yqXL1+S1KnTSPGSpeVNfb7kd3PLEV++mTVdvp3zmWldjlx5ZepXi/X993t1kgN7d5q212/cQt7uNyhB25nUGdZOHMQ8OFCjE/D09uzaIc1eeV0Ci5WQyMgImTF1kvTr0UXmfv+TfvNXPhwaJLdv3ZKR4z+V9H7pZc3qFTI0qJ/MmPudFC5S1N0/Alwoc5as0vnt3pIzVx6xiU1WL18ig/r3lBlfLZB8+QtK4cBiUueFRpI1a3a5efOGzPlimvTv+abMX7zKNAEZkpbceQvI8HHT7Y+dX+t6LzaX/73R1f7YO1WqBG2fFXhZPDqIcXBw8+bNGB/U19c3ru1J8j6ebP5G8N6QD6VJvepy9PAhKfNMeb3u4L490vfdwVKseEn9uF3HN2XBN3Plz8MHCQ6SmCrP1TA97tS1p84kHDqwTwcHjZu9Yt+WLSCHdHizu3Rq/bKcP3dWcuR8cLl0JD0qGMiQMdNjt6us439tBxIsOEifPv0Taw5sNpveJzIy8qkbZhW3b9/Wt76+fvZ1xUuVkfVrVknlqs9L2nTpZMPaVXIv7J6UKVfBjS1FfFN/N5vW/SyhISFSvETpaNtDQu7KqmU/SvaAHJIlaza3tBEJ4+yZU9K+RV1JmdJbihQvJW0795DMWbPbt29au0I2rlkhGfwzyrNVqstrbTuLd6rUbm1zUmNYO3EQ8+Bgw4YNLvtPw8LC9GJe56Uv/WwlagKpyeNHS8nSZSV/wUL29cNGjZOh770jL9apKsmSJZdUqVLJiLETJWeu3G5tL+LHiWN/SrdOreXevXu6a2n4RxN17UGUHxd+K599Ol4HDar+ZOzkzyVFihRubTPiT+FiJaTXu8MlR648cvXKZV1/ENSzg3wya6GkSeMj1es00IGCf6bM8vfxv2TuZ5PkzOl/JOiDce5uepJiWDw6MGzq634CGzp0qAwbNsy0rt+7g6R/ULBYybjRw+WP33+VTz+fa/omOHHsSDl8cL90ebuX+KVPL79sWi8L5n8lkz+fIwUKFhYriLyf4Kel26jrkVw8f05u374lm9evkeVLFsnEabPsAYJaf/3qVbly5ZJ8P2+OXLp4QT79/CtJaaFg+mZIhFiVqj/q3LKhdHi7r9Rt1Cza9n27tsngvm/K9HlLJHsO63Q1BWZ/UKMVX3osPuyyY01uVtQ68xxcv35dvvzySz0zolK8eHHp0KGD+Pk9TI8/TlBQkPTt29d8vLA4TdaYaE0Y86H8/ssmmTxjjikwOPPvKVn0/XyZ8+2Pkq/Ag4tbFSwcKPt275LFC76Rd4KGuLHViA8qC5Dj/7NCRYoWlyOHD8gP330t/f7/tU6bNp1ecubOI8VKlJYmdarKLxvXSe36Dd3cciQE1bUYkDO3nDtz+pHbCxd9UJuktlspOED8itMn8o4dO6RAgQIyYcIEPaeBWsaPH6/X7dq164nPV90HqmjRcbFKl4JK1KjAQL25T5w2UwJy5DRtDw0N1beG00XAvZJ5ic1C36atTL3O4eH3Hr3NZtPL47Yj6Qm5e1fOn/33sQWIJ48d1bf+FCi6lGHxSzbHKXPQp08fadKkiXz++eeSPPmDQ0REREinTp2kd+/esnnzZle3M8mY8NEIWbt6hYz8+BPdf6jmNFDSpk2rhyPlyZtPf4v8eNRwebvXOzoT88vG9XrOg9ETpri7+XCxz6dMlApVqumhinfv3pF1q1fInl3bZcyk6XL2zGnZsGa1lK9YWdJn8NfdCd/M/VIH0lHzICDpmTV1vC4yzJw1QK5euajnPfDy8pLqtV/Q2YHN61ZKuYrVJJ1vevn7xJ8yc8o4KV76GclbwBpdjgnFK3F+pru35iB16tSye/duCQwMNK0/dOiQlC9fXk/cE1sXboaLFVR/tsQj1wcFj5AGjZvq+6dP/SOffTpB9u/dJSF3QyRHrlzSsnV7qd+wiViFVWoOxowIll07/pCrly+JT9p0ujD19TYdpHzFKnL50kX5+MMh8ueRQ3Lr1k1dmV6qbDk9SVLuPA8nzbICK9UcjB02UA7u2yW3bt4QP78MUrRkGWndqbvuMrh08bxM+PB9OXXyuC5QzZQlq1R6rpa82qaTpPFJK1YS3zUHvX864rJjTXzJ/FmZZIODrFmzyldffSX16tUzrV+9erW0bdtWLly4EOuGWCU4QMxYJThAzFgpOIBnBAd9l7guOBjfJNAa3QqvvfaadOzYUT7++GOpUqWKXvfbb79J//795fXXX3d1GwEASFBGIq0VcGtwoIIC9YtTWQJVaxBVcd21a1cZPXq0q9sIAAA8OThQs7ht3bpVz1UwatQoOX78uF6vRiqkSRO/aR4AABKCl7UTB7EPDtSc36rWQM1vkC9fPilZ8sEYWwAAkgrD4sFBnOY5KFGihJw4ccL1rQEAwMI2b94sjRs3loCAAN19/+OPP5q2t2/fPto8Ci+88IJpHzX3UKtWrfQcQuq6SKpGMOo6PvEaHIwYMULeeecdWbZsmZw7d05fsdFxAQAgsV+y2ctFS2zcuXNHSpcuLVOmPH5eGxUMqM/eqOWbb74xbVeBwcGDB2XNmjX6c1oFHF26dIn/gsSGDR9M26omQnKs6OSqjACApMDLTf9vgwYN9PJf1ERo2bI9+sqsqst/1apVsn37dj3vkDJ58mT9ua0GE6iMRLwFB668QiMAAJ7G8OCag40bN0qWLFkkQ4YMUqtWLZ3Nz5gxo962ZcsW3ZUQFRgoderU0bNs/vHHH9KsWfSLd7ksOHj++efj8jQAACwnLCxML87f/uNyTSHVpdC8eXM9IECNFnzvvfd0pkEFBWrAwPnz53Xg4Ehd5sDf319vS5CrMm7btk0uXrwo9+/fN21T8x8AAJBYebkwdaCG/Q8bNsy0bsiQIXpKgNhq2bKl/b4aLViqVCk9lYDKJtSuXVtcJU7BwdKlS3XBg6p+VNWQjnUHUZMjAQCQWBku7FYICgqSvn37mta56krE+fPnl0yZMsmxY8d0cKBqEdSXdkdqskI1guFxdQouq7no16+fdOjQQQcHKoNw7do1+6IaAAAAHgYC6ou04+Kq4ODff/+VK1euSPbs2fXjypUr68/lnTt32vdZv369zvBXrFgxfjMHZ86ckZ49ezIjIgAgSfJyU0Gi+tKtsgBRTp48KXv27NE1A2pR3RMtWrTQWQBVczBgwAApWLCg1K9fX+9ftGhRXZfQuXNnmT59uoSHh0v37t11d0RMRyrEOXOgGrFjx464PBUAAI/n5aZ5DtRna9myZfWiqO4IdT84OFgXHO7bt09PI1C4cGE9uVG5cuXkl19+MWUi5s2bJ4GBgbqbQQ1hrFatmsyYMSNW7YhT5qBRo0b6CoyHDh3SBRHqokuOVMMBAEDs1KhRQ88Z9DirV69+4jFUhmH+/PnyNAzbf7XiMdR4ycceMI6TIF24GR7r5yDpirwf69MSSdjNkAdXfwWiBGaP327tD9Y+TO0/rcF1CkpiE6fMgfPQRQAAkhIvD54EKSHEquZA9V3cuHHD/nj06NG6KjKKqpgsVqyYa1sIAAA8NzhQfR2OszyNHDnSNHRRjaU8evSoa1sIAEACM1z4LzGKVbeCc3lCHMoVAADweF6J8zPdZeI8fTIAAEmVl8WDg1h1K6iRCI5TJUetAwAASUesuxXat29vn2whNDRU3nrrLfHx8dGPna86BQBAYmRY/ItvrIKDdu3amR63bt062j5cdAkAkNh5WTs2iF1wMGvWrPhrCQAA8AgUJAIA4MQgcwAAABx5WTw6iNNVGQEAQNJF5gAAACde1k4cEBwAAODMsHhwQLcCAAAwIXMAAIATr0R6wSRXITgAAMCJYe3YgOAAAABnXhYPDqg5AAAAJmQOAABw4mXxfgWCAwAAnBjWjg3oVgAAAGZkDgAAcOJl8dQBwQEAAE4Ma8cGdCsAAAAzMgcAADjxEmsjOAAAwIlh8X4FqwdHAADACZkDAACcGGJtBAcAADjxsni3AsEBAABODLE2ag4AAIAJmQMAAJwYFk8dEBwAAODEsHh0QLcCAAAwIXMAAIATL7E2ggMAAJwYdCsAAAA8ROYAAAAnhlgbwQEAAE4Mi3creExw4JcmhbubAA8Sci/S3U2ABylQs6+7mwAPE7L7U3c3IUnzmOAAAABP4SXWRnAAAIATg24FAADgyBBrs3rmBAAAOCFzAACAE8PiqQOCAwAAnHhZvGOBbgUAADzE5s2bpXHjxhIQEKCLIn/88UfTdpvNJsHBwZI9e3ZJnTq11KlTR/766y/TPlevXpVWrVqJr6+vpE+fXjp27Ci3b9+OVTsIDgAAeES3guGiJTbu3LkjpUuXlilTpjxy+5gxY+STTz6R6dOnyx9//CE+Pj5Sv359CQ0Nte+jAoODBw/KmjVrZNmyZTrg6NKlS+x+fpsKQzxAaIS7WwBPwiRIcBRQtZe7mwCLTYK0/MBFlx2rUYkscXqeyhwsXrxYmjZtqh+rj2uVUejXr5+88847et2NGzcka9asMnv2bGnZsqUcPnxYihUrJtu3b5fy5cvrfVatWiUNGzaUf//9Vz8/JsgcAAAQj8LCwuTmzZumRa2LrZMnT8r58+d1V0IUPz8/qVixomzZskU/VreqKyEqMFDU/l5eXjrTEFMEBwAAxGO3wqhRo/SHuOOi1sWWCgwUlSlwpB5HbVO3WbKYMxXJkycXf39/+z4xwWgFAADicbRCUFCQ9O1rvj6It7e3eDKCAwAA4pG3t7dLgoFs2bLp2wsXLujRClHU4zJlytj3uXjRXC8RERGhRzBEPT8m6FYAAMBDRiv8l3z58ukP+HXr1tnXqfoFVUtQuXJl/VjdXr9+XXbu3GnfZ/369XL//n1dmxBTZA4AAPCQGRJv374tx44dMxUh7tmzR9cM5M6dW3r37i0jRoyQQoUK6WBh8ODBegRC1IiGokWLygsvvCCdO3fWwx3Dw8Ole/fueiRDTEcqKAQHAAA4Mdw0Q+KOHTukZs2a9sdRtQrt2rXTwxUHDBig50JQ8xaoDEG1atX0UMVUqVLZnzNv3jwdENSuXVuPUmjRooWeGyE2mOcAHol5DuCIeQ6Q0PMcrDl82WXHqls0kyQ2ZA4AAHDiZe1LKxAcAADgKd0KnoLRCgAAwITMAQAAHjJawVMQHAAA4MSgWwEAAOAhMgcAADjxsnbigOAAAABnBt0KAAAAD5E5AADAiWHtxAHBAQAAzgyxNoIDAACceFk8dUDNAQAAMCFzAACAE0OsLc6Zg+PHj8ugQYPk9ddfl4sXL+p1K1eulIMHD7qyfQAAuCc6MFy0WCU42LRpk5QsWVL++OMPWbRokdy+fVuv37t3rwwZMsTVbQQAAJ4eHLz77rsyYsQIWbNmjaRMmdK+vlatWrJ161ZXtg8AALdMgmS46J9lag72798v8+fPj7Y+S5YscvnyZVe0CwAAtzES52e6ezMH6dOnl3PnzkVbv3v3bsmRI4cr2gUAABJTcNCyZUsZOHCgnD9/XgzDkPv378tvv/0m77zzjrRt29b1rQQAIAEZ1q5HjFtwMHLkSAkMDJRcuXLpYsRixYpJ9erVpUqVKnoEAwAAiZph7ejAsNlstrg++fTp07r+QAUIZcuWlUKFCsW5IaERcX4qkqCQe5HubgI8SEDVXu5uAjxMyO5P4/X420/ecNmxns3nJ5bIHAwfPlzu3r2rMwcNGzaUV199VQcGISEhehsAAImZYfHRCnEKDoYNG2af28CRChjUNgAAEvtoBcNFi2WGMqqeCFWI6ExNguTv7++KdgEA4DaGWFusgoMMGTLooEAthQsXNgUIkZGROpvw1ltvxUc7AQCAJwYHEydO1FmDDh066O4DP7+HRRZqpsS8efNK5cqV46OdAAAkHEMsLVbBQbt27fRtvnz59LDFFClSxFe7AABwG8Pi0UGcag6ef/55+/3Q0FC5d++eabuvr+/TtwwAACSe0QpqVEL37t31tRR8fHx0LYLjAgBAYmZYfLRCnIKD/v37y/r162XatGni7e0tX3zxha5BCAgIkLlz57q+lQAAJCDD2hMkxq1bYenSpToIqFGjhrzxxhvy3HPPScGCBSVPnjwyb948adWqletbCgAAPDdzcPXqVcmfP7+9vkA9VqpVqyabN292bQsBAEhohrVTB3EKDlRgcPLkSX1fXYDp+++/t2cU1OWcAQBIzAymT4491ZWgZkNU3n33XZkyZYqkSpVK+vTpo+sRAABA4vVUV2WM8s8//8jOnTt13UGpUqXidAyuyghHXJURjrgqIxL6qoz7/41+/aC4KpkzrViiINGZKkRUCwAASYEh1han4OBJl2UODg6Oa3sAAHA/QywtTsHB4sWLTY/Dw8N1gWLy5MmlQIECBAdP4cvPZ8gnE8dJq9ZtZUDQ++5uDhLA7p075Ou5M+XooYNy+fIl+Wj8J/J8zTr27Xfv3pGpn0yQTRvWyc0b1yV7QA559fXW0vyVlm5tN55e51eqSeeXn5M8AQ+uZnv4xHkZOWOl/PzbIcngm0YGd20ktSsFSq5sGeTytduydOM+GTZ1mdy8HWo/hto26b3X5PnyheV2SJjMW/qHDJ68RCIj77vxJ4Mlg4Pdu3dHW3fz5k1p3769NGvWzBXtsqQD+/fJwgXfSuHCRdzdFCSgkJC7UqhwEWn8UnN5t1/PaNsnjRsjO7dvlaEffqQDg21bfpOxoz6QTJmzSPUatdzSZrjGmQvXZfDkn+TYqUu6qr1144qyYEIXqdRytL7qbfbMfhI0YbEOGnJn95fJ77fU6/7X/0v9fC8vQxZ90lUuXLkpNduPk2yZ/eSLD9pIeESkDPl0qbt/vETNsHjqIE6jFR5FzXegZkkcPHiwqw5pKXfv3JGggf1lyLAR4utwtUskfVWqVZe3uvWSGrUeZgsc7d+7Wxq+2FTKla8gAQE5pGmLV6Vg4SJy6OD+BG8rXGvF5gOy+tdDcvzUJTl26qIMnbJUbt8Nkwql8smh4+fk9Xe+0Puc/PeybNr+pwz9dKk0rF5CkiV78NZdp3JRKZo/m3R4f47s+/OMzjgMn7pc3ny1uqRInszdP16iZjB9suvcuHFDL4i9kSOGS/Xqz0ulylXc3RR4mJKly8ovmzbIxYsX9CXTd27/Q07/87dUrFTV3U2DC6kswCv1y4lP6pTyx74H88g4802XSm7eCbV3GVQslU8OHDsrF6/esu+z5vfD4pcutRQrkD3B2o6kJ07dCp988onpsXrDOnfunHz11VfSoEEDV7XNMlauWC6HDx+S+d8tdHdT4IH6DXxfRn8wRJrUrynJkicXL8OQoMHDpWy58u5uGlygeMEA2Tinn6RKmVzXDLzW73M5cuJ8tP0ypveRoM4NZOYPv9vXZc3oKxevPAwMlItXbz7YlslX5GgC/ABJlCHWFqfgYMKECabHXl5ekjlzZmnXrp0EBQU98flhYWF6cWRL5q0v4mQ158+dkzGjP5TPPp9pyZ8fT7bg26/lwP69MnbiFMmWPUD27NohH49WNQeZpUIlMk2J3Z9/X5CKLUeJX9rU0qxOWfl8eBup12mSKUBI55NKFn/SVQ6fOCcjPlvu1vZahiGWFqfgIGrq5LgaNWqUrk9w9P7gITIoeKhYzaFDB+XqlSvS8pXm9nWRkZGyc8d2+fabebJ9935Jloy+Q6sKDQ2VaZMnykfjJ0vV557X61Tx4p9Hj8j8r2YTHCQBqnjwxOnL+v7uw6elXPHc0u31GtLjw2/1urRpvGXJlLfl1t1Qea3v5xIR8XAUgipELF/CPMdMFn/fB9suP8ggAG6bBCm2VHahb9++0TIHVlSxUiVZ+KO5qnjI+0GSN39+eaNjZwIDi4uMiJCIiAhdue5IFaTdv89QtaRIdRt5p0xuzxgsndpNwu5FyMu9P9O3jlRtwsCO9SVzhrRy6dqDGf3U0Mcbt0L0CAfEnWHx1EGMg4PmzR9+s32SRYsW/ed2lT53TqFbdfpkH5+0UqhQYdO61GnSSHq/9NHWI2lS8xj8e/qU/fHZM2fkz6OHxdfXT3cjlC33rHw68WPxTpVKsmcPkF07t8vKZUukZ9+Bbm03nt7wHk1k9W8H5fS5azoQeK1BealevpA0fnuqfrxsajdJnSqlvPH+HPH1SaUXRQUC9+/bZO2WwzoI+HJEO3l/0o+6BmFItxfls+83y71wi76puohh7dgg5sGBn8PwOlWAqCZCUuvKl39QFKWurXD9+vVYBREARA4fOijdOre3P5407iN927BxUwkePlJGjP5Ypk6eIEPfGyA3b97QAcOb3XpJ81dec2Or4QqZ/dPKlx+0lWyZfOXG7VA58NcZHRis/+OIPFeukB7SqBxaau5yLdIwWE6du6oDhBa9psmk91rKxtn95E6omgRpmwyfRl1CYjV06NBo3e5FihSRI0eO2Lsa+/XrJ99++62u3atfv75MnTpVsmbN6v4LLw0cOFCuXr0q06dPt6e9VT/522+/rec7GDt2bKwbYtXMAR6NCy/BERdeQkJfeOnP83dddqzC2dLEKjhYuHChrF271r5OzT6cKVMmfb9r166yfPlymT17tv6C3r17dz0o4LfffnNZe/X/GZcnzZw5U3799VdTf7i6r+oIqlSpEqfgAAAAj2G4779WwUC2bNmirVfzCH355Zcyf/58qVXrweyos2bNkqJFi8rWrVulUqVK7p0ESRVIRaU4HKl1FEkBAJJCQaLhon8q/a8uMeC4OA/nd/TXX39JQECA5M+fX1q1aiWnTp2yd9+raxnVqfNwNtXAwEDJnTu3bNmyxaU/f5yCgzfeeEM6duwo48eP1xkEtYwbN046deqktwEAgIfD91UXgOOi1j1KxYoVdZfBqlWrZNq0aXrqgOeee05u3bol58+fl5QpU0r69OlNz1H1Bmqb27sVPv74Y53yUAGBmhlRyZ49u/Tv318XSgAAkJgZRvwO33/cpHeOswyXKlVKBwt58uSR77//XlKnTi0JJU7BgSp+GDBggF5UekRRhYgAACQFhguP9ajh+zGlsgSFCxeWY8eOSd26deXevXt6ZKBj9uDChQuPrFFw64WXVFBAYAAAgOvdvn1bjh8/rrPz5cqVkxQpUsi6devs248ePaprEipXruwZMySqoRYqzaEapSIZR7t27XJF2wAAsNRohXfeeUcaN26suxLOnj0rQ4YM0aMBX3/9dV2roOr9VBeFv7+//mLeo0cPHRi4cqRCnDMH6qqMqvBQFUHs3r1bKlSoIBkzZpQTJ05wVUYAQKJnuPBfbPz77786EFATH7366qv6s1UNU1QXN4y68OGLL74oLVq0kOrVq+vuhCfNSpxgkyCpoRMqmlE/QLp06WTv3r16yEVwcLCeHOnTT2M/OQWTIMERkyDBEZMgIaEnQTpxKdRlx8qf+cG014lJnDIHqitBTXakqOpJNcRCadOmjXzzzTeubSEAAG4YrWC4aEmM4hQcqDSGyhAoavIFlfJQ1HjMOCQiAADwKIYLF8sEB2raxiVLluj7qvagT58+eojFa6+9Js2aNXN1GwEAQAKK02iFGTNm2KdJ7tatmy6Y+P3336VJkyby5ptvurqNAAAkLEMsLdYFieq6CiNHjpQOHTpIzpw5XdYQChLhiIJEOKIgEQldkPjPlcdf+yC28mSM2wRIiapbQV0tasyYMTpIAAAgKTIoSIy92rVry6ZNm1zfGgAAkDhrDtRER++++67s379fT+fo4+Nj2q5qDwAASKwMsbY4TYKkLrz02AMahkRGxr6/mJoDOKLmAI6oOUBC1xz8e811NQc5M3hbI3MQNVIBAAAkPbEKDkJCQvTVoNS8zlHXqA4LCzMVKw4fPlxSpUp8U0UCAPCQIVYWq+Bgzpw5snz5cntwoK6hULx4cT2FsnLkyBE9e6K6YhQAAImVYe3YIHajFebNmyddunQxrZs/f75s2LBBL2PHjpUFCxa4uo0AAMBTg4Njx45JyZIl7Y9V94FjcaK6dPOhQ4dc20IAABKYYfFrK8SqW+H69eumGoNLly5FK1R03A4AQGJkJNZPdXdkDtR0yQcOHHjs9n379rl0SmUAAODhwUHDhg0lODhYQkNDHzmSYdiwYdKoUSNXtg8AgARnuPBfkp8E6cKFC1KmTBlJmTKldO/eXQoXLqzXHz16VI9cUNdb2L17t2TNmjXWDWESJDhiEiQ4YhIkJPQkSOdvhrvsWNl8U0iSrjlQH/rq0sxdu3bV0ydHxRVqVsS6devK1KlT4xQYAADgSQyxtljPkJgvXz5ZtWqVXL16VY9eUAoWLCj+/v7x0T4AAJAYpk9WVDCghi4CAJDUGBZPHcQ5OAAAIKkyLN6xEKvRCgAAIOkjcwAAgDNDLI3gAAAAJ4ZYG90KAADAhMwBAABODIunDggOAABwYli8Y4FuBQAAYELmAAAAJ4a1EwdkDgAAgBmZAwAAnBhkDgAAAB4icwAAgBPD4qMVCA4AAHBiWDs2oFsBAACYkTkAAMCJIdZGcAAAgDNDLI1uBQAAYELmAAAAJ4bFUwcEBwAAODGsHRvQrQAAAMzIHAAA4MQQayM4AADAmSGWRnAAAIATw+LRATUHAADAhMwBAABODGsnDsSw2Ww2dzcCD4SFhcmoUaMkKChIvL293d0cuBnnAxxxPiAhERx4kJs3b4qfn5/cuHFDfH193d0cuBnnAxxxPiAhUXMAAABMCA4AAIAJwQEAADAhOPAgqshoyJAhFBtB43yAI84HJCQKEgEAgAmZAwAAYEJwAAAATAgOAACACcEBkEhs3LhRDMOQ69ev68ezZ8+W9OnTP/Vx1TF//PFHF7QQ8aV9+/bStGlTdzcDFkJwEMM/TPUGqpYUKVJI1qxZpW7dujJz5ky5f/++JBZ58+aViRMnursZSep8cFxeeOEFdzcNCeT8+fPSq1cvKViwoKRKlUq/J1StWlWmTZsmd+/elcTAVcElkiYuvBRD6o1/1qxZEhkZKRcuXJBVq1bpN4eFCxfKkiVLJHny6L/K8PBwHUwg6Z4PjuI6xEwNGFLn1aPOIXieEydO6EBAfbCOHDlSSpYsqV/7/fv3y4wZMyRHjhzSpEmTaM/j/QCJCZmDGFJ//NmyZdN/+M8884y899578tNPP8nKlSt1BK6ob4/qm4N6Y/Dx8ZEPP/xQr1frChQoIClTppQiRYrIV199ZTp21PMaNGggqVOnlvz58+ugw5F646lVq5benjFjRunSpYvcvn3bvr1GjRrSu3dv03NUGlJ9y43a/s8//0ifPn3s33Tx9OeD45IhQwa9Tf1uv/jiC2nWrJmkSZNGChUqpANI5+4Bde6UK1dOH+vXX3/VF9bp2bOnZMmSRX8brVatmmzfvj1W7VLnpDo/1fPVeTRs2DCJiIiwb//rr7+kevXqenuxYsVkzZo1LvytWMPbb7+tA7kdO3bIq6++KkWLFtW/65deekmWL18ujRs3fuz7gQoCO3bsKPny5dN/y+r9YNKkSabjq3369u2rgw/1tz5gwAAdQD4pC1imTBkZOnSo/fH48eN14KL+71y5cul2R71nqHPwjTfe0NdpiHo/iHquOg/feecd/V6nnluxYkW9PyxGzXOA/9auXTvbSy+99MhtpUuXtjVo0EDfV7/OLFmy2GbOnGk7fvy47Z9//rEtWrTIliJFCtuUKVNsR48etY0bN86WLFky2/r16+3HUM/LmDGj7fPPP9f7DBo0SO9z6NAhvf327du27Nmz25o3b27bv3+/bd26dbZ8+fLpdkV5/vnnbb169TK1TbU5ap8rV67YcubMaRs+fLjt3LlzeoHrz4eo11P9rufPn2/766+/bD179rSlTZtWvwbKhg0b9D6lSpWy/fzzz7Zjx47pbWq/gIAA24oVK2wHDx7U/0+GDBmiPe/atWv68axZs2x+fn72/3fz5s02X19f2+zZs/X5p46dN29e29ChQ/X2yMhIW4kSJWy1a9e27dmzx7Zp0yZb2bJl9TEXL14cz7+1pOHy5cs2wzBso0aNeuK+j3o/uHfvni04ONi2fft224kTJ2xff/21LU2aNLbvvvvO/ryPPvpIv+4//PCDfg/o2LGjLV26dKZzLk+ePLYJEyZEey8aMmSI/bHart5nTp48qd8zihQpYuvataveFhYWZps4caI+X6LeD27duqW3derUyValShV9Pqlzc+zYsTZvb2/bn3/+6ZLfIRIHgoOn/DB47bXXbEWLFrW/GfTu3du0Xf2Rde7c2bTulVdesTVs2ND+WD3vrbfeMu1TsWJF+x/yjBkz9JuFChKiLF++3Obl5WU7f/58jIKDx72hIPbU71QFbz4+Pqblww8/tL+eKsCLol43tW7lypWmD/kff/zRtI8KIufNm2dfpz5IVLAwZsyYGAUH6kN/5MiRprZ+9dVXOrBUVq9ebUuePLntzJkz9u2qTQQHMbd161b9+1JBvyMV3EedBwMGDHjs+8GjdOvWzdaiRQv7Y/V6Rb3mSnh4uA42YxscOFuwYIFuZxTn80dRAYw6tx3PkahzKygo6Ik/C5IOOjmfknoPcEzRly9f3rT98OHDugvAkeqvdE4lVq5cOdrjPXv22I9RunRpneJzPIYqhjx69KguhkLCqlmzpk4ZO/L397ffL1WqlP2+et3UJXYvXrxo2t/xXDl+/Ljuk1avaxTVP12hQgX9+sfE3r175bfffrN3Z0WlqENDQ3WRnDqOSi8HBAQ89rxD3Gzbtk3/PbZq1Uqn5R/3fqBMmTJFFzOfOnVKQkJC5N69e7pLQFFp/nPnzulUfhTVhaGOE9vJbNeuXSujRo2SI0eO6Ms9q+6lqHNBdXc9iuq+VOdM4cKFTevVz6S6OGAdBAdPSb3hqv7DKI4f4AnJy8sr2puH+rBB/FCvs6pUfxznwjMVQDqPbHH1uaL6k1WNQfPmzaNtUzUGeHrqNVevpQrKHamaA0XVEfzXa/ztt9/q/vxx48bpwCxdunQyduxY+eOPP1z69/7333/Liy++KF27dtXBogpcVV2LqndQwcjjggN1DiVLlkx27typbx2lTZs2Vm1E4kZB4lNYv369jrRbtGjx2H1UsZL6NudIPVbFYI62bt0a7bF6btQx1LfCO3fumI6h3iBUQZOSOXNm/Y0jior+Dxw4YDqmKohU6+F5ogpWHc8V9WavChKdz5XHUYWI6kNLfYA5L+pcUefR6dOnTeeJ83mH/6a+PathzJ9++qnp7zGm1OtbpUoVXRxYtmxZ/dqorFEUPz8/yZ49uylYUN/41Ye1I+e/d5UZOHnypP2x2l8FoyoIqVSpks4EnD179onvB6pNap3KcjmfQ6roFtZB5iCGVFpNjW12HMqoUnYqOm/btu1jn9e/f39d0az+6OrUqSNLly6VRYsW6ZSfowULFujUoapQnzdvnk5Tfvnll3qbSlWqq7G1a9dOVxRfunRJevToIW3atLF3KaiRDKrCWVVLqw8aVakcNVmOY4Xz5s2bpWXLlrpCPlOmTPHyu7LS+eBIpX/j+jtV3zDVtzx1vqhveblz55YxY8boFLD6thcTwcHB+nxUz3355Zd1QKCCShUkjhgxQp9/6kNCnUfq26r6QHn//ffj1F4rmzp1qu7+UX+v6u9RdSGp37UK5FQKX41AeRw1cmXu3LmyevVqnXFUI5fU8xyzj2qI9OjRo/W+gYGBj/xbVn/vapSUGhmhRjWo197xm776MFfB5eTJk/U+KiiZPn16tPcDlSlYt26d7rZU2QR1fqj3G/WepgIL9b6l3m/UPurnbNSokUt/l/Bg7i56SCwFaOpXpRZV0JU5c2ZbnTp1dBWyqgCP8rjCrqlTp9ry58+vC84KFy5smzt3rmm7ep4azVC3bl1dFawqzB2rl5V9+/bZatasaUuVKpXN399fFzlGVRdHFa+pAka1TVVIq2pq54LELVu26Ap59X/w0rvmfHBcVDX4484DVfilCsAeVVgYJSQkxNajRw9bpkyZ9GtUtWpV27Zt2+zbn1SQqKxatUoXwaZOnVpXoleoUEEXtEZRo2GqVatmS5kypT4X1f4UJMbe2bNnbd27d9ejhtTftRqNon7XqrL/zp07ep9H/V5DQ0Nt7du3169b+vTp9d/su+++q4sJHQsQVXGxev3UPn379rW1bdvWVJB448YNXQyt9smVK5ceoeJckDh+/Hhd3KjOhfr16+v3HefzThVCqyJFtT7quVEjKtT7kPrZ1DGaNWum34NgHVyy2QOoPszFixczPSoAwCNQcwAAAEwIDgAAgAkFiR6Anh0AgCchcwAAAEwIDgAAgAnBAQAAMCE4AAAAJgQHAADAhOAAAACYEBwAAAATggMAAGBCcAAAAMTR/wG2GM/PsiPVtgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, test_predictions), annot=True, fmt='g', \n",
    "            xticklabels=categories, yticklabels=categories, cmap=\"Blues\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2afa193",
   "metadata": {},
   "source": [
    "### Tuner Results\n",
    "\n",
    "The tuned model achieved an overall accuracy of 75.9%, matching the non-tuned model’s performance.\n",
    "It performed best for the Graduate class (precision = 0.77, recall = 0.94, F1 = 0.85), while the Enrolled class showed lower recall (0.28).\n",
    "Overall, the model demonstrated good generalization and consistent accuracy across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7a7b6ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.83      0.73      0.78       206\n",
      "    Enrolled       0.49      0.28      0.36       116\n",
      "    Graduate       0.77      0.94      0.85       342\n",
      "\n",
      "    accuracy                           0.76       664\n",
      "   macro avg       0.70      0.65      0.66       664\n",
      "weighted avg       0.74      0.76      0.74       664\n",
      "\n",
      "\n",
      "Model overall accuracy: 75.90%\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_predictions, target_names=categories))\n",
    "\n",
    "acc = accuracy_score(y_test, test_predictions)\n",
    "print(\"\\nModel overall accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3175a1e",
   "metadata": {},
   "source": [
    "### ROC-AUC Result\n",
    "\n",
    "The tuned model achieved a ROC-AUC of 0.877, slightly higher than the non-tuned models 0.874.\n",
    "Class separation is therefore marginally better with tuning, though the difference is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "81f067e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8770188517510201"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, model.predict(X), multi_class=\"ovr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e70b2eb",
   "metadata": {},
   "source": [
    "### Logistic Regression (Tuner)\n",
    "\n",
    "The Logistic Regression implementation is based on the official scikit-learn source:\n",
    "https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/linear_model/_logistic.py\n",
    ".\n",
    "GPT was used to refine and simplify the implementation, ensuring adherence to best practices and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "37b8ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = map(lambda y: np.argmax(y, axis=1) if y.ndim > 1 else y, [y_train, y_test])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train, X_test = scaler.fit_transform(X_train), scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7cad1a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=2000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "test_pred = log_reg.predict(X_test)\n",
    "test_probs = log_reg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "61dd86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, test_pred)\n",
    "roc_auc = roc_auc_score(y_test, test_probs, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ec020073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Overall Accuracy: 0.7440\n",
      "ROC-AUC: 0.8414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.78      0.76      0.77       206\n",
      "    Enrolled       0.48      0.21      0.29       116\n",
      "    Graduate       0.76      0.92      0.83       342\n",
      "\n",
      "    accuracy                           0.74       664\n",
      "   macro avg       0.67      0.63      0.63       664\n",
      "weighted avg       0.72      0.74      0.72       664\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Model Overall Accuracy: {acc:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\\n\")\n",
    "print(classification_report(y_test, test_pred, target_names=['Dropout', 'Enrolled', 'Graduate']))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, test_pred), annot=True, fmt='g', cmap='Blues',\n",
    "            xticklabels=['Dropout', 'Enrolled', 'Graduate'],\n",
    "            yticklabels=['Dropout', 'Enrolled', 'Graduate'])\n",
    "plt.title(\"Confusion Matrix – Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b216516",
   "metadata": {},
   "source": [
    "### Model Comparison: Neural Network (Tuner) vs. Logistic Regression (Tuner)\n",
    "\n",
    "- Neural Network (tuned): Accuracy 75.2%, ROC-AUC 0.877\n",
    "- Logistic Regression (tuned): Accuracy 74.4%, ROC-AUC 0.841\n",
    "\n",
    "Conclusion: Both models performed similarly, but the Neural Network showed slightly better class separation and higher recall for minority classes, reflecting its advantage in capturing non-linear relationships.\n",
    "\n",
    "### Logistic Regression: Non-Tuned vs. Tuned\n",
    "\n",
    "- Non-tuned model: Accuracy 75.9%, ROC-AUC 0.86\n",
    "- Tuned model: Accuracy 74.4%, ROC-AUC 0.841\n",
    "\n",
    "Conclusion: The non-tuned Logistic Regression model generalized slightly better. Tuning did not improve performance and led to a lower recall for the Enrolled class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d3ec8f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Previous qualification (grade)', 'Admission grade', 'Displaced',\n",
       "       'Educational special needs', 'Debtor', 'Tuition fees up to date',\n",
       "       'Gender', 'Scholarship holder', 'Age at enrollment', 'International',\n",
       "       'Unemployment rate', 'Inflation rate', 'GDP', 'single', 'partnered',\n",
       "       'prev_partnered', 'admission_general', 'admission_transfer',\n",
       "       'admission_special/international', 'high_priority', 'studyfield_stem',\n",
       "       'studyfield_business_social', 'studyfield_arts&comm', 'is_daytime',\n",
       "       'prevqual_basic', 'prevqual_secondary', 'prevqual_higher',\n",
       "       'nationality_europe', 'nationality_africa', 'nationality_south_america',\n",
       "       'nationality_north_america', 'nationality_asia',\n",
       "       'mother_qualification_basic', 'mother_qualification_secondary',\n",
       "       'mother_qualification_higher', 'father_qualification_basic',\n",
       "       'father_qualification_secondary', 'father_qualification_higher',\n",
       "       'mother_occ_academic', 'mother_occ_technical_admin',\n",
       "       'mother_occ_service_manual', 'mother_occ_unskilled_other',\n",
       "       'father_occ_academic', 'father_occ_technical_admin',\n",
       "       'father_occ_service_manual', 'father_occ_unskilled_other', 'avg_grade',\n",
       "       'success_rate', 'total_enrolled', 'no_evaluation_total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f52c88",
   "metadata": {},
   "source": [
    "### Prediction Tuner Example\n",
    "\n",
    "To test the model, a single example student profile was created with features such as grades, demographics, and socioeconomic background.\n",
    "The trained model was used to predict the most likely outcome (Dropout, Enrolled, or Graduate) and the associated class probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0697756e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Predicted outcome: Enrolled\n",
      "\n",
      "Probabilities by class:\n",
      "['Dropout', 'Enrolled', 'Graduate']\n",
      "[0.15013142 0.43693513 0.4129335 ]\n"
     ]
    }
   ],
   "source": [
    "tester_row = {\n",
    "    \"Previous qualification (grade)\": 150.0,\n",
    "    \"Admission grade\": 140.0,\n",
    "    \"Displaced\": 0,\n",
    "    \"Educational special needs\": 0,\n",
    "    \"Debtor\": 0,\n",
    "    \"Tuition fees up to date\": 1,\n",
    "    \"Gender\": 1,\n",
    "    \"Scholarship holder\": 0,\n",
    "    \"Age at enrollment\": 20,\n",
    "    \"International\": 0,\n",
    "    \"Unemployment rate\": 5.2,\n",
    "    \"Inflation rate\": 1.2,\n",
    "    \"GDP\": 2.3,\n",
    "    \"single\": 1,\n",
    "    \"partnered\": 0,\n",
    "    \"prev_partnered\": 0,\n",
    "    \"admission_general\": 1,\n",
    "    \"admission_transfer\": 0,\n",
    "    \"admission_special/international\": 0,\n",
    "    \"high_priority\": 0,\n",
    "    \"studyfield_stem\": 1,\n",
    "    \"studyfield_business_social\": 0,\n",
    "    \"studyfield_arts&comm\": 0,\n",
    "    \"is_daytime\": 1,\n",
    "    \"prevqual_basic\": 1,\n",
    "    \"prevqual_secondary\": 0,\n",
    "    \"prevqual_higher\": 0,\n",
    "    \"nationality_europe\": 1,\n",
    "    \"nationality_africa\": 0,\n",
    "    \"nationality_south_america\": 0,\n",
    "    \"nationality_north_america\": 0,\n",
    "    \"nationality_asia\": 0,\n",
    "    \"mother_qualification_basic\": 0,\n",
    "    \"mother_qualification_secondary\": 1,\n",
    "    \"mother_qualification_higher\": 0,\n",
    "    \"father_qualification_basic\": 0,\n",
    "    \"father_qualification_secondary\": 0,\n",
    "    \"father_qualification_higher\": 1,\n",
    "    \"mother_occ_academic\": 0,\n",
    "    \"mother_occ_technical_admin\": 1,\n",
    "    \"mother_occ_service_manual\": 0,\n",
    "    \"mother_occ_unskilled_other\": 0,\n",
    "    \"father_occ_academic\": 0,\n",
    "    \"father_occ_technical_admin\": 0,\n",
    "    \"father_occ_service_manual\": 0,\n",
    "    \"father_occ_unskilled_other\": 1,\n",
    "    \"avg_grade\": 14.5,\n",
    "    \"success_rate\": 0.8,\n",
    "    \"total_enrolled\": 11,\n",
    "    \"no_evaluation_total\": 0\n",
    "}\n",
    "\n",
    "tester_row = pd.DataFrame([tester_row])\n",
    "\n",
    "result = model.predict(tester_row)[0]\n",
    "result_text = categories[np.argmax(result)]\n",
    "\n",
    "np.set_printoptions(precision=9, suppress=True)\n",
    "\n",
    "print(f\"Predicted outcome: {result_text}\\n\")\n",
    "print(\"Probabilities by class:\")\n",
    "print(categories)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bc588b",
   "metadata": {},
   "source": [
    "### Student Tuner Outcome GUI\n",
    "\n",
    "For demonstration purposes, a simple GUI was implemented using Tkinter.\n",
    "The interface allows users to input student-related features (with default example values provided) and receive a predicted student outcome (Dropout, Enrolled, or Graduate) directly from the trained model.\n",
    "\n",
    "This GUI code was generated entirely by GPT, as I had not previously worked with Tkinter and wanted a quick and simple way to build an interface for testing predictions.\n",
    "The correctness was verified by ensuring that all model input features are included in the GUI and that the predicted class output matches the model’s expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0d9f15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"best_model_student2.keras\")\n",
    "\n",
    "default_values = {\n",
    "    \"Previous qualification (grade)\": 150.0,\n",
    "    \"Admission grade\": 140.0,\n",
    "    \"Displaced\": 0,\n",
    "    \"Educational special needs\": 0,\n",
    "    \"Debtor\": 0,\n",
    "    \"Tuition fees up to date\": 1,\n",
    "    \"Gender\": 1,\n",
    "    \"Scholarship holder\": 0,\n",
    "    \"Age at enrollment\": 20,\n",
    "    \"International\": 0,\n",
    "    \"Unemployment rate\": 5.2,\n",
    "    \"Inflation rate\": 1.2,\n",
    "    \"GDP\": 2.3,\n",
    "    \"single\": 1,\n",
    "    \"partnered\": 0,\n",
    "    \"prev_partnered\": 0,\n",
    "    \"admission_general\": 1,\n",
    "    \"admission_transfer\": 0,\n",
    "    \"admission_special/international\": 0,\n",
    "    \"high_priority\": 0,\n",
    "    \"studyfield_stem\": 1,\n",
    "    \"studyfield_business_social\": 0,\n",
    "    \"studyfield_arts&comm\": 0,\n",
    "    \"is_daytime\": 1,\n",
    "    \"prevqual_basic\": 1,\n",
    "    \"prevqual_secondary\": 0,\n",
    "    \"prevqual_higher\": 0,\n",
    "    \"nationality_europe\": 1,\n",
    "    \"nationality_africa\": 0,\n",
    "    \"nationality_south_america\": 0,\n",
    "    \"nationality_north_america\": 0,\n",
    "    \"nationality_asia\": 0,\n",
    "    \"mother_qualification_basic\": 0,\n",
    "    \"mother_qualification_secondary\": 1,\n",
    "    \"mother_qualification_higher\": 0,\n",
    "    \"father_qualification_basic\": 0,\n",
    "    \"father_qualification_secondary\": 0,\n",
    "    \"father_qualification_higher\": 1,\n",
    "    \"mother_occ_academic\": 0,\n",
    "    \"mother_occ_technical_admin\": 1,\n",
    "    \"mother_occ_service_manual\": 0,\n",
    "    \"mother_occ_unskilled_other\": 0,\n",
    "    \"father_occ_academic\": 0,\n",
    "    \"father_occ_technical_admin\": 0,\n",
    "    \"father_occ_service_manual\": 0,\n",
    "    \"father_occ_unskilled_other\": 1,\n",
    "    \"avg_grade\": 14.5,\n",
    "    \"success_rate\": 0.8,\n",
    "    \"total_enrolled\": 11,\n",
    "    \"no_evaluation_total\": 0\n",
    "}\n",
    "\n",
    "def predict():\n",
    "    try:\n",
    "        data = {f: float(entries[f].get()) for f in default_values.keys()}\n",
    "        df = pd.DataFrame([data])\n",
    "        pred = model.predict(df, verbose=0)[0]\n",
    "        result_text = f\"Predicted outcome probabilities:\\nDropout: {pred[0]:.2f}, Enrolled: {pred[1]:.2f}, Graduate: {pred[2]:.2f}\"\n",
    "        result_label.config(text=result_text)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Student Success Predictor\")\n",
    "root.geometry(\"600x700\")\n",
    "\n",
    "main_frame = tk.Frame(root)\n",
    "main_frame.pack(fill=tk.BOTH, expand=1)\n",
    "\n",
    "canvas = tk.Canvas(main_frame)\n",
    "canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=1)\n",
    "\n",
    "scrollbar = tk.Scrollbar(main_frame, orient=tk.VERTICAL, command=canvas.yview)\n",
    "scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "canvas.configure(yscrollcommand=scrollbar.set)\n",
    "canvas.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "\n",
    "frame_inside = tk.Frame(canvas)\n",
    "canvas.create_window((0, 0), window=frame_inside, anchor=\"nw\")\n",
    "\n",
    "entries = {}\n",
    "\n",
    "for f, example in default_values.items():\n",
    "    row = tk.Frame(frame_inside)\n",
    "    lab = tk.Label(row, width=28, text=f+\": \", anchor=\"w\")\n",
    "    ent = tk.Entry(row)\n",
    "    ent.insert(0, str(example))\n",
    "    hint = tk.Label(row, width=12, text=f\"(e.g. {example})\", anchor=\"w\", fg=\"grey\")\n",
    "\n",
    "    row.pack(side=tk.TOP, fill=tk.X, padx=5, pady=2)\n",
    "    lab.pack(side=tk.LEFT)\n",
    "    ent.pack(side=tk.LEFT, expand=tk.YES, fill=tk.X)\n",
    "    hint.pack(side=tk.RIGHT)\n",
    "\n",
    "    entries[f] = ent\n",
    "\n",
    "predict_button = tk.Button(frame_inside, text=\"Predict\", command=predict, bg=\"#4CAF50\", fg=\"white\", font=(\"Helvetica\", 10, \"bold\"))\n",
    "predict_button.pack(pady=10)\n",
    "\n",
    "result_label = tk.Label(frame_inside, text=\"Prediction will appear here\", font=(\"Helvetica\", 12), wraplength=500, justify=\"left\")\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "def _on_mouse_wheel(event):\n",
    "    canvas.yview_scroll(int(-1 * (event.delta / 120)), \"units\")\n",
    "\n",
    "canvas.bind_all(\"<MouseWheel>\", _on_mouse_wheel)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
